# JAVA

## 并发

### 线程

- 状态转换

  ![](THREAD_STATE_CHANGE.jpg)

### 关键字与JDK源码

  - #### synchronized [参考链接](http://cmsblogs.com/?p=2071)
    
    - 应用 : A a = new A();
      - 锁普通方法 (锁的是A的实例)
      - 锁静态方法 (锁的是A.class)
      - 锁代码块
        - 对象(a,锁的是A的实例)
        - 类 (A.class,锁的是A.class)
    - 问:当两个线程同时执行A类中的普通方法和静态方法是否互斥?答:不互斥,因为是两把不同的锁
    - 原理(字节码层次,在java语言存在两种语法)
      - 语法
        - 锁 --> 代码块
          - 代码块在源码被编译成bytecode时,会在同步代码的入口位置和退出位置分别插入monitorenter,monitorexit字节指令
        - 锁 --> 方法
          - 在字节码层面没有特别的指令实现被synchronized修饰的方法,而是在Class文件的方法表中将该方法的access_flags字段中的synchronized标志位置1,表示该方法是同步方法并使用调用该方法的对象或者方法所属的Class在jvm的内部对象表示Klass作为对象锁
      - 对象头
        - synchronized用的锁时存在**对象头**里的
        - 对象头主要包括两部分数据(Mark Work, Klass Pointer)
          - Mark Work (标记字段)
          - Klass Pointer (类型指针)
    
  - ##### volatile

  - **LookSupport**

      - 线程等待唤醒机制(相当于wait/notify 加强版)
      - LockSupport通过许可（permit）实现线程挂起、挂起线程唤醒功能。permit可以理解为每个已启动线程维持的一个int类型状态位counter。线程分别通过执行LockSupport静态方法park()、unPark()方法来完成挂起、唤醒操作。
      - 主要方法
          - java.util.concurrent.locks.LockSupport#park()
              - 唤醒条件
                  - unpark()
                      - 当线程执行park时,判断状态位counte为1,表示拥有许可,立马放行,并将状态位counter设置为0
                      - 当线程执行park时,判断状态位counter为0,表示未获得许可,线程阻塞
              - 响应中断
                  - 当其他线程调用了t.interrupt(),locksupport.park()会效应中断
          - java.util.concurrent.locks.LockSupport#unpark(Thread thread)
            - 现将当前状态位counter设置为1
            - 判断当前线程是否被挂起
                - 挂起,则唤起线程,并将counter设为0
                - 未挂起,无任何操作
    - 面试题
      - 先执行unpark在执行park程序会出现什么情况?
        - 先执行unpark,执行线程与locksupport关联的许可(permit)会被设置成1,当执行park时,会进行状态位判断,因为许可被设置成了1,所以表示当前执行的线程拥有许可,立马放行,并将许可设置成0
      - 先唤醒两次,在阻塞两次会出现什么情况?
        - 会阻塞线程
        - 当执行两次unpark时,会将状态位设置为1,且仅为1,状态位counter最大只能设置为1,也就是许可permit最大为1,所以不管先执行几次unpark,都只能唤醒一个park
    
- **ThreadLocal**

     - private final int threadLocalHashCode = nextHashCode();

          - 从方法来看,每次生成ThreadLocal都会进行递增HASH_INCREMENT
     
          - ```java
               private static int nextHashCode() {
                   return nextHashCode.getAndAdd(HASH_INCREMENT);
          }
               ```

     - private static AtomicInteger nextHashCode = new AtomicInteger();

          - 类变量 也就是说每个ThreadLocal实例的nextHashCode是不一样的

     - private static final int HASH_INCREMENT = 0x61c88647;

     - static class ThreadLocalMap
     
          -  每一个Thread都会维护一个只属于当前Thread的ThreadLocalMap
     
          - ```java
               // ThreadLocalMap内部又维护了一个Entry,继承了WeakReference<ThreadLocal<?>>
               static class Entry extends WeakReference<ThreadLocal<?>> {
                   /** The value associated with this ThreadLocal. */
                   // 这个value值就是当前线程要存储的值
                   Object value;
                   Entry(ThreadLocal<?> k, Object v) {
                       // 而传进来的ThreadLocal 交给WeakReference,最后会放入 引用队列
                       super(k);
                       value = v;
                   }
               }
               private static final int INITIAL_CAPACITY = 16;
          private Entry[] table;
               private int size = 0;
               private int threshold;
               ```

          - ```
             
               ```
     
     - java.lang.ThreadLocal#set
     
          - ```java
               public void set(T value) {
                   // 获取当前线程
                   Thread t = Thread.currentThread();
                   ThreadLocalMap map = getMap(t);
                   if (map != null)
                       map.set(this, value);
                   else
                       // 第一次进来map肯定是为null,所以要创建个map
                       createMap(t, value);
               }
               // 获取ThreadLocalMap ,从这里可以看出,Thread中维护着一个ThreadLocalMap
               ThreadLocalMap getMap(Thread t) {
                   return t.threadLocals;
               }
               // Thread中的ThreadLocals 超时是null,此处创建一个ThreadLocalMap,key为ThreadLocal, value为set传入的值
               void createMap(Thread t, T firstValue) {
                   t.threadLocals = new ThreadLocalMap(this, firstValue);
               }
               // ThreadLocalMap的构造器,承接上边的createMap
               ThreadLocalMap(ThreadLocal<?> firstKey, Object firstValue) {
                   // 初始
                   table = new Entry[INITIAL_CAPACITY];
                   int i = firstKey.threadLocalHashCode & (INITIAL_CAPACITY - 1);
                   table[i] = new Entry(firstKey, firstValue);
                   size = 1;
                   setThreshold(INITIAL_CAPACITY);
               }
               // java.lang.ThreadLocal.ThreadLocalMap#set
               private void set(ThreadLocal<?> key, Object value) {
                   Entry[] tab = table;
                   int len = tab.length;
                 	// 初始len=16 ,并且len始终是2^n ,只有这样len-1的二进制表示的就是低位连续的N个1,
                 	// 假设当前线程初始值 threadLocalHashCode = 1640531527  十进制
                 	// len - 1 的       二进制是 1111, 进行补码 00000000 00000000 00000000 00001111
                   // threadLocalHashCode 的二进制位(直接补码) 01100001 11001000 10000110 01000111
                 	// 那么下边的计算得出结果为
                   // 00000000 00000000 00000000 00000111  --> 0111 -> 1*2^2 + 1*2^1 + 1*2^0-> 0+4+2+1=7
                 	// 分析到这也就确定了,当前线程占得table的坑是7,之后当前线程无论多少次ThreadLocal#set 都不会在改变
                 	// 原因在new ThreadLocal<T> 创建实例 时 threadLocalHashCode 的数值已经确定了.
                 	// 需要注意的是 每次new ThreadLocal<T>时threadLocalHashCode 都会以原子性做一个递增操作,而每次都是增加1640531527
                   int i = key.threadLocalHashCode & (len-1);
                   for (Entry e = tab[i];
                        e != null;
                        e = tab[i = nextIndex(i, len)]) {
                    	// e.get() 获取的是一个弱引用的ThreadLocal 	
                     	// 也就是或 当前线程绑定的ThreadLocalMap绑定的弱引用ThreadLocal
                       ThreadLocal<?> k = e.get();
                     	// 如果相等表示是替换value值
                       if (k == key) {
                           e.value = value;
                           return;
                       }
                       // 进入这个条件,也就是说明 出现了gc,并清除了弱引用
                       if (k == null) {
                          
                          replaceStaleEntry(key, value, i);
                          return;
                       }
                   }
                   tab[i] = new Entry(key, value);
                   int sz = ++size;
                   // 如果没有清理并且操作次数大于等于要扩容的条件则进行扩容
                   if (!cleanSomeSlots(i, sz) && sz >= threshold)
                       rehash();
               }
               // java.lang.ThreadLocal.ThreadLocalMap#cleanSomeSlots
               private boolean cleanSomeSlots(int i, int n) {
                   boolean removed = false;
                   Entry[] tab = table;
                   int len = tab.length;
                   do {
                       i = nextIndex(i, len);
                       Entry e = tab[i];
                       if (e != null && e.get() == null) {
                           n = len;
                           removed = true;
                           i = expungeStaleEntry(i);
                       }
                   } while ( (n >>>= 1) != 0);
                   return removed;
               }
               // 调整table大小,删除无用的数据(也就是e.get == null)情况
               // java.lang.ThreadLocal.ThreadLocalMap#rehash
               private void rehash() {
                   expungeStaleEntries();
                   // Use lower threshold for doubling to avoid hysteresis
                   if (size >= threshold - threshold / 4)
                       resize();
               }
               // java.lang.ThreadLocal.ThreadLocalMap#resize
               private void resize() {
                   Entry[] oldTab = table;
                   int oldLen = oldTab.length;
                   int newLen = oldLen * 2;
                   Entry[] newTab = new Entry[newLen];
                   int count = 0;
                   for (int j = 0; j < oldLen; ++j) {
                       Entry e = oldTab[j];
                       if (e != null) {
                           ThreadLocal<?> k = e.get();
                           if (k == null) {
                               e.value = null; // Help the GC
                           } else {
                               int h = k.threadLocalHashCode & (newLen - 1);
                               while (newTab[h] != null)
                                   h = nextIndex(h, newLen);
                               newTab[h] = e;
                               count++;
                           }
                       }
                   }
                   setThreshold(newLen);
                   size = count;
                   table = newTab;
               }
               
               // java.lang.ThreadLocal.ThreadLocalMap#replaceStaleEntry
               private void replaceStaleEntry(ThreadLocal<?> key, Object value,
                                              int staleSlot) {
                   Entry[] tab = table;
                   int len = tab.length;
                   Entry e;
                   // 记录将要删除的slot,这个在清理时是个重要的字段
                   int slotToExpunge = staleSlot;
                   //以staleSlot开始, 向前遍历N个e != null的节点,
                   for (int i = prevIndex(staleSlot, len); (e = tab[i]) != null; i = prevIndex(i, len))
                       if (e.get() == null)
                           // 如果e不为空,e的Key也就是ThreadLocal为空,记录下要删除的slot
                           slotToExpunge = i;
                   
               	// 以staleSlot开始,向后遍历N个 e!=nul的节点
                   for (int i = nextIndex(staleSlot, len);(e = tab[i]) != null; i = nextIndex(i, len)) {
                       ThreadLocal<?> k = e.get();
                       if (k == key) {
                           e.value = value;
                           tab[i] = tab[staleSlot];
                           // staleSlot是调用方法时的计算的槽,此处e赋值给他,代表这个就是最新的了
                           tab[staleSlot] = e;
                           if (slotToExpunge == staleSlot)
                               slotToExpunge = i;
                           cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);
                           return;
                       }
                       if (k == null && slotToExpunge == staleSlot)
                           slotToExpunge = i;
                   }
                   // If key not found, put new entry in stale slot
                   tab[staleSlot].value = null;
                   tab[staleSlot] = new Entry(key, value);
                   // If there are any other stale entries in run, expunge them
                   if (slotToExpunge != staleSlot)
                       cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);
               }
               
               // java.lang.ThreadLocal.ThreadLocalMap#expungeStaleEntry 
               // 清理方法,不做注释了
               private int expungeStaleEntry(int staleSlot) {
                   Entry[] tab = table;
                   int len = tab.length;
                	// 置空
                   tab[staleSlot].value = null;
                   tab[staleSlot] = null;
                   size--;
               
                   Entry e;
                   int i;
                   // 继寻找e!=null的下一个节点,
                   for (i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) {
                       ThreadLocal<?> k = e.get();
                       if (k == null) {
                           e.value = null;
                           tab[i] = null;
                           size--;
                       } else {
                           int h = k.threadLocalHashCode & (len - 1);
                           if (h != i) {
                               tab[i] = null;
                               while (tab[h] != null)
                                   h = nextIndex(h, len);
                               tab[h] = e;
                           }
                       }
                   }
                   return i;
               }
               
               ```
     
     - java.lang.ThreadLocal#get
     
          - ```java
               public T get() {
                   Thread t = Thread.currentThread();
                   ThreadLocalMap map = getMap(t);  // Thread.threadLocals
                   if (map != null) {
                       ThreadLocalMap.Entry e = map.getEntry(this);
                       if (e != null) {
                           @SuppressWarnings("unchecked")
                           T result = (T)e.value;
                           return result;
                       }
                   }
                   return setInitialValue();
               }
               // java.lang.ThreadLocal.ThreadLocalMap#getEntry
               private Entry getEntry(ThreadLocal<?> key) {
                   int i = key.threadLocalHashCode & (table.length - 1);
                   Entry e = table[i];
                   if (e != null && e.get() == key)
                       return e;
                   else
                       return getEntryAfterMiss(key, i, e);
               }
               
               // java.lang.ThreadLocal.ThreadLocalMap#getEntryAfterMiss
               // 该方法通过一个while条件获取entry,直到 找到与当先线程相等的ThreadLocal
               // 如果找不到,直接返回空
               // 该方法也涉及删除无效的entry
               private Entry getEntryAfterMiss(ThreadLocal<?> key, int i, Entry e) {
                   Entry[] tab = table;
                   int len = tab.length;
                   while (e != null) {
                       ThreadLocal<?> k = e.get();
                       if (k == key)
                           return e;
                       if (k == null)
                           expungeStaleEntry(i);
                       else
                           i = nextIndex(i, len);
                       e = tab[i];
                   }
                   return null;
               }
               ```
     
     - java.lang.ThreadLocal#remove
     
          - ```
               private void remove(ThreadLocal<?> key) {
                   Entry[] tab = table;
                   int len = tab.length;
                   int i = key.threadLocalHashCode & (len-1);
                   for (Entry e = tab[i];
                        e != null;
                        e = tab[i = nextIndex(i, len)]) {
                       if (e.get() == key) {
                           e.clear();
                           expungeStaleEntry(i);
                           return;
                       }
                   }
               }
               ```

### J.U.C

- 中断
  - 关键方法
    - java.lang.Thread#isInterrupted()   --- public boolean isInterrupted()
      - 会调用private native boolean isInterrupted(boolean ClearInterrupted) 本地方法,true代表重置,false代表不重置,此处ClearInterrupted=false
      -  测试线程是否已经中断。线程的中断状态不受该方法的影响
    - java.lang.Thread#interrupted   --- public static boolean interrupted()
      - 会调用private native boolean isInterrupted(boolean ClearInterrupted) 本地方法,true代表重置,false代表不重置,此处ClearInterrupted=true
      - 测试当前线程是否已经中断。如果线程处于中断状态返回true，否则返回false。同时该方法将清除的线程的中断状态。即，如果连续两次调用该方法，则第二次调用将返回 false。该方法可用于清除线程中断状态使用。
      - 
    - java.lang.Thread#interrupt ---- public void interrupt()
      - 中断线程
- 
  
 - AQS (抽象的队列同步器) [源码解读](https://www.cnblogs.com/waterystone/p/4920797.html)

    - ![](CLH队列.png)

    - AQS中维护一个CLH变种的双端队列,和一个volatile 修饰的state字段

       - state 字段 0 值表示空闲没有任何线程占用,大于0表示有线程正在使用
       - Node 内部类
          - static final Node SHARED = new Node();   共享锁标识
          - static final Node EXCLUSIVE = null; // 共享锁
          - static final int CANCELLED =  1; 
          - static final int SIGNAL    = -1;
          - static final int CONDITION = -2;
          - static final int PROPAGATE = -3;
          - volatile int waitStatus; //初始值 0
          - volatile Node prev; 前指针
          - volatile Node next; 后指针
          - volatile Thread thread; 当前node的线程
          - Node nextWaiter;
       - Node head 头结点
       - Node tail 尾节点

    - 流程 (以ReentrantLock为例)

       - new ReentrantLock() 初始化,默认使用非公平锁(NonfairSync)

       - lock

         - ```java
           final void lock() {
               if (compareAndSetState(0, 1))
                   setExclusiveOwnerThread(Thread.currentThread());
               else
                   acquire(1);
           ```

           

         - 当state=0时也就是说没有任何线程占用锁,cas操作成功,将state从0设置成1,并且返回true,然后设置拥有锁的线程,也就是当前线程

         - 当state !=0,也就是已经有线程占有锁了,表示cas操作失败,进入acquire(1);方法

         - ```java
           public final void acquire(int arg) {
               if (!tryAcquire(arg) &&
                   acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
                   // 当acqioreQueued返回true则表示当前线程不是被unpark唤醒的,是被其他线程中断唤醒的,所以要自我中断一次,将中断标志位设为true
                   // 原因是因为,当前线程在阻塞时没有及时响应中断信号,现在要进行补偿,这样的话,如果该线程在lock代码块内部调用sleep()之类的阻塞方法
                   // 就可以抛出异常,响应中断
                 selfInterrupt();
           }
           ```
           
         - 此时tryAcquire(arg)会再次尝试获取一下锁,如果成功后边的方法就不用再执行了

           - ```java
             protected final boolean tryAcquire(int acquires) {
                 return nonfairTryAcquire(acquires);
             }
             final boolean nonfairTryAcquire(int acquires) {
                 // 获取当前线程
                 final Thread current = Thread.currentThread();
                 int c = getState();
                 // 如果c = 0 也就是state=0尝试cas强锁
                 if (c == 0) {
                     // 强锁成功的话设置当前线程为持有锁线程并返回true
                     if (compareAndSetState(0, acquires)) {
                         setExclusiveOwnerThread(current);
                         return true;
                     }
                 }
                 // 如果c!=0 也就是state!=0判断,持有锁的线程是不是当前线程(重入锁逻辑)
                 else if (current == getExclusiveOwnerThread()) {
                     int nextc = c + acquires;
                     if (nextc < 0) // overflow
                         throw new Error("Maximum lock count exceeded");
                     setState(nextc);
                     return true;
                 }
                 return false;
             }
             ```

         - 当tryAcquire(arg) 失败,则继续向后执行

           - ```java
             private Node addWaiter(Node mode) {
             	// 创建一个node节点,mode 区分为 共享锁/独占锁,此处是以ReentrantLock为例,
             	// 所以此处是独占锁Node.EXCLUSIVE
                 Node node = new Node(Thread.currentThread(), mode);
                 // 将尾节点赋值给pred
                 Node pred = tail;
                 if (pred != null) {
                     node.prev = pred;
                     // 将新创建的node设置成尾节点
                     if (compareAndSetTail(pred, node)) {
                         pred.next = node;
                         return node;
                     }
                 }
                 enq(node);
                 return node;
             }
             private Node enq(final Node node) {
             	// 一个自旋
                 for (;;) {
                     Node t = tail;
                     // 第一次进来t 肯定是null
                     if (t == null) { // Must initialize
                     	// 此处创建了一个node实例并将这个实例放置到头结点
                         // 该节点也叫哨兵节点/傀儡节点,只是占位使用
                         if (compareAndSetHead(new Node()))
                         	如果CAS设置成功 将将尾节点赋值
                             tail = head;
                     } else {
                         //当 t != null时进入此处
                         node.prev = t;
                         //CAS 操作将尾节点设置成enq入参的node
                         if (compareAndSetTail(t, node)) {
                             // CAS 操作成功,设置t的next节点为node并返回
                             t.next = node;
                             return t;
                         }
                     }
                 }
             }
             ```

             - enq第一次图(t==null)![](enq_one.png)
             - enq第二次图(t!=null)![](enq_two.png)

         - enq方法执行完成后执行acquireQueued(final Node node, int arg) 方法

           - ```java
             final boolean acquireQueued(final Node node, int arg) {
                 boolean failed = true;
                 try {
                     boolean interrupted = false;
                     // 自旋
                     for (;;) {
                         // 获取node的前置节点,该方法会抛出一个npe异常
                         final Node p = node.predecessor();
                         //如果node的前置节点是头结点,则再次尝试抢锁
                         if (p == head && tryAcquire(arg)) {
                             // 抢锁成功设置当前节点为头节点也就是傀儡节点
                             setHead(node);
                             // 将之前的头结点next引用改为null,方便gc
                             // 换句话说就是之前的头结点p已经给任何node没有应用关系了
                             p.next = null; // help GC
                             failed = false;
                             return interrupted;
                         }
                         // 当shouldParkAfterFailedAcquire=true
                         // parkAndCheckInterrupt=false (表示未被中断)
                         // parkAndCheckInterrupt=true (表示被中断) 并赋值interrupted = true;
                         // 此时线程已被前一个node节点唤醒,并且前一个节点已经晋升为头结点,当前线程开始进入下一次自旋
                         if (shouldParkAfterFailedAcquire(p, node) &&
                             parkAndCheckInterrupt())
                             interrupted = true;
                     }
                 } finally {
                     if (failed)
                         cancelAcquire(node);
                 }
             }
             private void setHead(Node node) {
                 head = node;
                 node.thread = null;
                 node.prev = null;
             }
             private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) {
                 int ws = pred.waitStatus;
                 if (ws == Node.SIGNAL)
                     /*
                      * This node has already set status asking a release
                      * to signal it, so it can safely park.
                      */
                     return true;
                 if (ws > 0) {
             		// 当被取消的线程才会进入这里
                     do {
                         node.prev = pred = pred.prev;
                     } while (pred.waitStatus > 0);
                     pred.next = node;
                 } else {
             		// waitStatus的默认值是0,所以第一次进来会进入这里
                     // 执行一个CAS操作,将waitStatus 赋值成SINNAL(-1)
                     compareAndSetWaitStatus(pred, ws, Node.SIGNAL);
                 }
                 return false;
             }
             private final boolean parkAndCheckInterrupt() {
                 // 挂起线程 阻塞在这里了,等待被unpark
                 LockSupport.park(this);
                 // 获取当前线程是否被中断过,并恢复默认中断状态(false)
                 return Thread.interrupted();
             }
             ```

       - 释放锁

         - ```java
           public void unlock() {
               sync.release(1);
           }
           public final boolean release(int arg) {
               if (tryRelease(arg)) {
                   Node h = head;
                   if (h != null && h.waitStatus != 0)
                       unparkSuccessor(h);
                   return true;
               }
               return false;
           }
           protected final boolean tryRelease(int releases) {
               int c = getState() - releases;
               // 在释放锁时,如果不是当前线程占有的锁,则抛出异常
               if (Thread.currentThread() != getExclusiveOwnerThread())
                   throw new IllegalMonitorStateException();
               boolean free = false;
               // 如果c==0表示可以释放锁了,如果非0表示当前线程是重入锁
               if (c == 0) {
                   free = true;
                   setExclusiveOwnerThread(null);
               }
               // 直接setState值,而不是使用CAS,因为reentranLock的addWaiter(Node.EXCLUSIVE) 用的是排它锁,
               // 所以此时直接set即可,此时是没有线程来抢锁的
               setState(c);
               return free;
           }
           // node 传进来的是头结点,也是当前线程的node节点
           private void unparkSuccessor(Node node) {
                   int ws = node.waitStatus;
                   if (ws < 0)
                       compareAndSetWaitStatus(node, ws, 0);
                   Node s = node.next;
                   if (s == null || s.waitStatus > 0) {
                       s = null;
                       for (Node t = tail; t != null && t != node; t = t.prev)
                           if (t.waitStatus <= 0)
                               s = t;
                   }
                   if (s != null)
                       // 唤醒下一个线程
                       
                       LockSupport.unpark(s.thread);
               }
           ```

- ThreadPoolExecutor
  - 构造方法参数
    - int corePoolSize       
    - int maximumPoolSize
    - long keepAliveTime
    - TimeUnit unit
    - BlockingQueue<Runnable> workQueue
    - ThreadFactory threadFactory
    - RejectedExecutionHandler handler
    
  - 成员变量和类变量

    - ```java
      // 初始 -536870912
      // 该字段控制状态,ctl 封装了 两个字段
      // workerCount 有效的线程数量
      // runState 该字段表明当前线程池 是否是在运行或者停止等等
      // ctl一个变量同时存储runState和workerCount，其中runState占用高3位，workCount占用低29位
      // 每增加一个线程则ctl原子性加一
      private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));
      private static final int COUNT_BITS = Integer.SIZE - 3;  // 29
      // 00011111 11111111 11111111 11111111
      private static final int CAPACITY   = (1 << COUNT_BITS) - 1; // 536870911
      // runState is stored in the high-order bits 
      // 11100000 00000000 00000000 00000000
      private static final int RUNNING    = -1 << COUNT_BITS; // -536870912
      // 00000000 00000000 00000000 00000000
      private static final int SHUTDOWN   =  0 << COUNT_BITS; // 0
      // 00100000 00000000 00000000 00000000
      private static final int STOP       =  1 << COUNT_BITS; // 536870912
      // tidying  [ˈtaɪdiɪŋ]  使整洁;使整齐 ;使有条理;整理
      // 01000000 00000000 00000000 00000000
      private static final int TIDYING    =  2 << COUNT_BITS; // 1073741824
      // terminated [ˈtɜːmɪneɪtɪd] 终止,结束
      // 01100000 00000000 00000000 00000000
      private static final int TERMINATED =  3 << COUNT_BITS; // 1610612736
      
      // Packing and unpacking ctl
      // 解析出来 runState
      // CAPACITY取反 高三位 变成了 111
      // c 如果在 -1 到 -536870912 之间 则表示线程是在运行中状态
      private static int runStateOf(int c)     { return c & ~CAPACITY; }
      // worker线程数量
      private static int workerCountOf(int c)  { return c & CAPACITY; }
      private static int ctlOf(int rs, int wc) { return rs | wc; }
      ```

  - ![大体流程](线程池流程.png)

  - 知识点

    - ThreadPoolExecutor中的内部类Worker简单描述下

      - ```java
        private final class Worker extends AbstractQueuedSynchronizer, implements Runnable {
        	// 通过构造方法可以看出,这个线程是通过工厂创建出来的,如果用户自定义线程工程,则使用用户的线程工厂,
            // 否则使用默认的工厂创建一个新的线程
            final Thread thread;
            // 通过构造方法可以看出,这个存放的就是线程池提交进来要执行的任务
        	Runnable firstTask;
            // 任务计数器
        	volatile long completedTasks;
        
        	Worker(Runnable firstTask) {
                setState(-1); // inhibit interrupts until runWorker
                this.firstTask = firstTask;
                this.thread = getThreadFactory().newThread(this);
            }
            // 省略重写的AbstractQueuedSynchronizer方法
            // 省略实现的Runnable方法
            
            // 下边就是Worker自己的方法了,可以看出Worker类本身就是一把锁
            
        	public void lock()        { acquire(1); }
        	public boolean tryLock()  { return tryAcquire(1); }
        	public void unlock()      { release(1); }
        	public boolean isLocked() { return isHeldExclusively(); }
        
        	void interruptIfStarted() {
        	    Thread t;
            	if (getState() >= 0 && (t = thread) != null && !t.isInterrupted()) {
                	try {
                    	t.interrupt();
                	} catch (SecurityException ignore) {
                	}
            	}
        	}
        }
        ```

      - Worker为什么要继承AbstractQueuedSynchronizer?意义何在?

        - ```java
          //下边是重写AbstractQueuedSynchronizer的方法
          // 该方法重写之后,只是简单的判断了下 state的值是否等于0
          protected boolean isHeldExclusively() {
              return getState() != 0;
          }
          
          protected boolean tryAcquire(int unused) {
              if (compareAndSetState(0, 1)) {
                  setExclusiveOwnerThread(Thread.currentThread());
                  return true;
              }
              return false;
          }
          // 独占锁,在释放锁时无需考虑线程安全,所以直接将占用锁的线程置空,直接调用setState方法,将state置为0
          protected boolean tryRelease(int unused) {
              setExclusiveOwnerThread(null);
              setState(0);
              return true;
          }	
          ```

      - Worker为什么要实现Runnable接口?

        - ```java
          // 实现了Runnable接口的方法
          public void run() {
              runWorker(this);
          }
          // 被run方法调用
          final void runWorker(Worker w) {
              Thread wt = Thread.currentThread();
              Runnable task = w.firstTask;
              w.firstTask = null;
              w.unlock(); // allow interrupts
              boolean completedAbruptly = true;
              try {
                  while (task != null || (task = getTask()) != null) {
                      w.lock();
                      if ((runStateAtLeast(ctl.get(), STOP) ||(Thread.interrupted() 
                           && runStateAtLeast(ctl.get(), STOP))) &&  !wt.isInterrupted()) 
                          wt.interrupt();
                      try {
                          beforeExecute(wt, task);
                          Throwable thrown = null;
                          try {
                              task.run();
                          } catch (RuntimeException x) {
                              thrown = x; throw x;
                          } catch (Error x) {
                              thrown = x; throw x;
                          } catch (Throwable x) {
                              thrown = x; throw new Error(x);
                          } finally {
                              afterExecute(task, thrown);
                          }
                      } finally {
                          task = null;
                          w.completedTasks++;
                          w.unlock();
                      }
                  }
                  completedAbruptly = false;
              } finally {
                  processWorkerExit(w, completedAbruptly);
              }
          }
          ```

          


# spring

## 事务

## MVC调用过程

## Bean生命周期

## Bean 循环依赖

## spring.handles 文件

## BeanFactory 和 FactoryBean<T>

## spring一些类说明

### class

- AbstractAutowireCapableBeanFactory
  - 实例化bean
  - 属性填充
  - 初始化bean
  - 三级缓存
- DefaultListableBeanFactory
- AbstractApplicationContext
- LazyInitializationBeanFactoryPostProcessor
- AbstractBeanDefinition
- PostProcessorRegistrationDelegatez
- SimpleApplicationEventMulticaster
- ConfigurationClassPostProcessor
- CommonAnnotationBeanPostProcessor
  - 类层次
    - 继承 InitDestroyAnnotationBeanPostProcessor   
    - 实现 InstantiationAwareBeanPostProcessor
    - 实现 BeanFactoryAware
    - 实现 Serializable
  - 
- AutowiredAnnotationBeanPostProcessor
  - 间接实现两种BeanPostProcessor
    - SmartInstantiationAwareBeanPostProcessor
      - determineCandidateConstructors(构造器实例化推断)
        - 调用时机:实例化之前
        - 在实例化bean之前调用,用来推断是否是通过有参构造器实例化还是用无参构造器初始化.
          - AbstractAutowireCapableBeanFactory#autowireConstructor(有参数构造器构建)
          - AbstractAutowireCapableBeanFactory#instantiateBean (无参构造器实例化)
        - lookup处理,如果存在lookup注解,则包装一个 LookupOverride override = new LookupOverride(method, lookup.value())类,然后将lookup包装后实例 放入 RootBeanDefinition.methodOverrides(字段中维护了一个Set集合,说明可以有多个lookup注解) 字段中,便于以后使用,CGLIB提升.
      - postProcessProperties
        - 调用时机:实例化之后,填充属性
        - 属性注入 包括@autowired  @value  @javax.inject.Inject
        - 内部类
          - AutowiredFieldElement extends InjectionMetadata.InjectedElement
          - AutowiredMethodElement extends InjectionMetadata.InjectedElement
          - 以上两个类包装 要注入的属性
    - MergedBeanDefinitionPostProcessor
      - postProcessMergedBeanDefinition
        - 调用时机:目标bean实例化后
  - 实现 BeanFactoryAware,主要作用 aware回调 setBeanFactory
  - 实现 PriorityOrdered 接口
    - 用于排序,该接口继承Order接口,无任何方法,算是个标识,在排序逻辑中PriorityOrdered比Order接口更强
- SimpleTypeConverter
- ResourceEditorRegistrar
  - registerCustomEditors
- PropertyPlaceholderHelper
- SmartInitializingSingleton
- PropertySourcesPropertyResolver
- AbstractPropertyResolver
- AbstractBeanFactory
- SimpleInstantiationStrategy
- InitDestroyAnnotationBeanPostProcessor

### interface

- InstantiationAwareBeanPostProcessor
- MergedBeanDefinitionPostProcessor
  - void postProcessMergedBeanDefinition(RootBeanDefinition beanDefinition, Class<?> beanType, String beanName)
    - 在bean实例化之后,立即调用可以修改beandefinition中的properties ,或缓存一些meta信息例如
  - void resetBeanDefinition(String beanName) 
    - 该方法是根据beanName 重置beandefinition
- BeanPostProcessor
  - Object postProcessBeforeInitialization(Object bean, String beanName)
    - 该方法在bean属性注入之后执行,自定义 init方法或InitializingBean的afterPropertiesSet方法之前
    - 返回一个原始bean或包装后的bean,如果返回null,就不会在执行后续的BeanPostProcessors的子类了
  - Object postProcessAfterInitialization(Object bean, String beanName)
    - 在执行InitializingBean#afterPropertiesSet()方法或自定义init方法后执行
    - 返回一个原始的bean或包装过的bean,如果返回null,就不会在执行后续的BeanPostProcessors的子类了
- BeanDefinition
- ApplicationContext
- BeanFactoryPostProcessors
- Lifecycle
- DisposableBean
- ApplicationContextInitializer
- ConversionService
- ObjectFactory<T>
  - objectfactory设计是用来对特定bean进行加工的，比如需要进行aop代理，需要对bean个性化的时候可以用objectfactory包装一下，objectprovider一般是spring内部实现某一个功能时可能有考虑不到的地方，spring抽象一个接口类型然后通过objectprovide来进行延长查找你实现了这些接口的类，一般会设计成链式调用，我个人的理解是objectfactory用来增强bean的功能，objectprovide+特点功能扩展接口，来实现把我们的功能和spring内部逻辑整合，比如@configurationpropertys不能解析spel表达式但是spring提供了扩展接口和objectprovide功能，我通过这2个地方扩展出来使得@configurationpropertys也能像@value一样支持spel表达式（springboot2.3才支持的！）
- InstantiationStrategy
- InjectionMetadata
- CglibSubclassingInstantiationStrategy
- DestructionAwareBeanPostProcessor

## Spring boot是如何内嵌TOMCAT的?

## Spring annotation

- @LookUp,单例引用原型(prototype)
  - 解释:Spring容器中单例A通过@Autowired或@resource 引入原型Bean,会出现原型bean变成了单例,而不是每次调用都会创建成新的实例所以lookup可以解决

# DUBBO

# MYSQL

## 索引

### BTree索引

####  MyISAM

-   MyISAM索引文件和数据文件是分离的
-   B+Tree叶节点的data域存放的是数据记录的地址。
-   在索引检索的时候，首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其 data 域的值，然后以 data 域的值为地址读取相应的数据记录。这被称为“非聚簇索引”。

#### InnoDB

-   其数据文件本身就是索引文件。
-   其表数据文件本身就是按B+Tree组织的一个索引结构，树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。这被称为“聚簇索引（或聚集索引）”。
-   其余的索引都作为辅助索引，辅助索引的data域存储相应记录主键的值而不是地址，这也是和MyISAM不同的地方。**在根据主索引搜索时，直接找到key所在的节点即可取出数据；在根据辅助索引查找时，则需要先取出主键的值，再走一遍主索引。** **因此，在设计表的时候，不建议使用过长的字段作为主键，也不建议使用非单调的字段作为主键，这样会造成主索引频繁分裂。**

 - ## [哈希索引](https://www.zhihu.com/question/67094336)

   	-   **底层的数据结构就是哈希表，因此在绝大多数需求为单条记录查询的时候，可以选择哈希索引，查询性能最快**
         	-   **mysql的 Memory存储引擎显示的支持了哈希索引**
            	-   **InnoDB引擎有一个特殊的功能叫做自适应哈希索引,当Innodb注意到默写索引值被使用的非常频繁时,他会在内存中机遇B-tree索引只上在创建一个哈希索引,这样就能让b-tree也具有哈希索引的一些优点,注:这是完全自动的,内部行为,用户无法控制和配置的,如果有必要可以关闭这个功能.**
   
- 辅助索引

  - 空间索引,主要用于地理空间数据类型
  - 全文索引,查找文本中的关键字,用于全文检索
  - 普通索引,最基本的索引,没有限制,唯一的任务就是加快对数据的访问速度.
  - 唯一索引,与普通索引类似,但是唯一索引值必须唯一,允许空值,单是是组合索引,则列值的组合必须唯一.
  - 主键索引,innodb聚簇索引
  - 组合索引
  
- 拓展

    - [索引下推(index conditoin pushdown 简称ICP)](https://blog.csdn.net/sinat_29774479/article/details/103470244)
        - 概述
            - 在不使用ICP的情况下，在使用**非主键索引（又叫普通索引或者二级索引）**进行查询时,存储引擎通过索引检索到数据,然后返回给MySQL服务器，服务器然后判断数据是否符合条件 。
            - 在使用ICP的情况下,如果存在某些被索引的列的判断条件时,MySQL服务器将这一部分判断条件传递给存储引擎,然后由存储引擎通过判断索引是否符合MySQL服务器传递的条件,只有当索引符合条件时才会将数据检索出来返回给MySQL服务器 
        - 注意项
            - innodb引擎只适用于二级索引(辅助索引), 因为innodb的聚簇索引会将正行数据读到innodb的缓冲区,ICP的主要目的减少IO次数就是去了意义,因为数据已经在内存中了,不需要在读取了
            - 引用子查询不能下推
            - 调用存储过程的条件不能下推,因为存储引擎无法调用位于Mysql服务器中的存储过程
            - 触发条件不能下推
        - 工作过程
            - 不使用: 获取下一行数据,首先读取索引信息,然后根据索引将正行数据读出来,然后通过where条件判断当前条件是否符合
            - 使用: 获取下一行索引信息,检索索引中的存储列信息是否符合索引条件,如果符合将整行数据读出来,如果不符合则跳过读取下一行,用剩余的判断条件,判断慈航数据是否符合,符合则返回数据

## 事务

### ACID

- **原子性（Atomicity）：** 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；
- **一致性（Consistency）：** 执行事务后，数据库从一个正确的状态变化到另一个正确的状态；
- **隔离性（Isolation）：** 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；
  - **持久性（Durability）：** 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。

### **并发事务带来的问题**

- **脏读（Dirty read）** 
  - 当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是不正确的。
  - 指一个线程中的事务读取到了另外一个线程中未提交的数据。
- **丢失修改（Lost to modify）**
  
  -  指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。 例如：事务1读取某表中的数据A=20，事务2也读取A=20，事务1修改A=A-1，事务2也修改A=A-1，最终结果A=19，事务1的修改被丢失。
- **不可重复读（Unrepeatableread）**  <!--**mysql的默认级别**--> 
  - 指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。
  - 指一个线程中的事务读取到了另外一个线程中提交的update的数据。
- **幻读（Phantom read）**
  -  幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。
  - 指一个线程中的事务读取到了另外一个线程中提交的insert的数据。
- **特别说明不可重复读的重点是修改比如多次读取一条记录发现其中某些列的值被修改，幻读的重点在于新增或者删除比如多次读取一条记录发现记录增多或减少了。**

- **隔离级别**

  - **READ-UNCOMMITTED(读取未提交)：** 最低的隔离级别，允许读取尚未提交的数据变更，**可能会导致脏读、幻读或不可重复读**。

  - **READ-COMMITTED(读取已提交)：** 允许读取并发事务已经提交的数据，**可以阻止脏读，但是幻读或不可重复读仍有可能发生**。

  - **REPEATABLE-READ(可重复读)：** 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，**可以阻止脏读和不可重复读，但幻读仍有可能发生**。

  - **SERIALIZABLE(可串行化)：** 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，**该级别可以防止脏读、不可重复读以及幻读**。

    

  - | 隔离级别         | 脏读 | 不可重复读 | 幻影读 |
    | ---------------- | ---- | ---------- | ------ |
    | READ-UNCOMMITTED | √    | √          | √      |
    | READ-COMMITTED   | ×    | √          | √      |
    | REPEATABLE-READ  | ×    | ×          | √      |
    | SERIALIZABLE     | ×    | ×          | ×      |

  - 特别说明mysql默认的隔离级别是 **可重复读**  使用的是next-key lock锁因此可以避免幻读产生,所以说mysql的可重复读已经完全可以保证事务的隔离要求.既达到了sql标准的可串行化隔离级别
  
- 事物的开始时间

  - 一般我们会认为begin/start transaction 是事物的开始时间点,其实是错误的,事务的真正开始时间点(LSN) 是start transaction 之后执行的第一条语句,不管什么语句,不管成功与否.但是如果你想要达到将 start transaction 作为事务开始的时间点，那么我们必须使用 2
    1. **START TRANSACTION** 时，是第一条语句的执行时间点，就是事务开始的时间点，第一条select语句建立一致性读的snapshot；
    2. **START TRANSACTION WITH consistent snapshot** 时，则是立即建立本事务的一致性读snapshot，当然也开始事务了；
  
- 总结

  - 原子性: undo log,实现回滚
  - 持久性: redo log 从而达到故障后恢复
  - 隔离性: 使用锁和mvcc,使用的优化思想有读写分离,读读并行,读写并行
  - 一致性: 通过回滚,以及恢复,和在并发环境下的隔离达到的一致性

## [锁](https://blog.csdn.net/Saintyyu/article/details/91269087?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-1.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-1.control)

- 表锁

  - 存储引擎支持
    - innodb
    - Myisam
  - 概要
    - 对整张表枷锁
    - 实现简单,资源消耗较少
    - 加锁快
    - 不会出现死锁
    - **触发锁冲突的概率较高**

- 行锁
  - 存储引擎支持
    - innodb
    - Myisam
  - 概要
    - 只对行加锁
    - 减少数据库操作冲突
    - 并发度高
    - 加锁开销大,加锁慢
    - **会出现死锁**
  - 行锁也分几种
    - **Record Lock**:   对索引项加锁,锁定符合条件的行,**其他事务不能修改和删除加锁项**
    - **Gap Lock:**对索引项的**'间歇'**进行加锁,锁定的范围(对第一条记录之前的间歇或最后一条将要记录后的间歇加锁),不包含索引项本身,其他事务不能再缩范围内插入数据,**这样就防止别的事务新增幻影行.**
    - **Next-Key Lock:** 锁定索引项本身和索引范围,既Record lock + gap lock的结合,可解决幻读的问题
- 以上三种锁注意事项
    - innodb对于行的查询使用next-key lock
    - Next-locking keying为了解决Phantom Problem幻读问题
    - 当查询的索引含有唯一属性时，将next-key lock降级为record key
    - Gap锁设计的目的是为了阻止多个事务将记录插入到同一范围内，而这会导致幻读问题的产生
    - 有两种方式显式关闭gap锁：（除了外键约束和唯一性检查外，其余情况仅使用record lock） A. 将事务隔离级别设置为RC B. 将参数innodb_locks_unsafe_for_binlog设置为1
  
- 锁分类

  - 共享锁(S)

    - **Share Locks**,也可称之为读锁
    - 例如事务T对数据A加S锁,则事务T只能读A,其他事务也只能对数据A加S锁,而不能加X锁,直到T释放了A锁.

  - 排它锁(X)

    - **Exclusive lock**又称之为写锁
    - 例如事务T对数据A加X锁,则只允许T读取和修改数据A,其他事务不能再对数据A进行任何类型的锁,直到T释放了A上的锁.

  - [意向锁](https://dev.mysql.com/doc/refman/8.0/en/innodb-locking.html#innodb-intention-locks)(**表级**)

    - 当一个事务需要给自己需要的某个资源加锁的时候,如果遇到一个共享锁正在锁定自己需要的资源的时候,自己可以在加一个共享锁,**不过不能加排他锁.**但是,如果遇到自己需要锁定的资源已经被一个排它锁占有之后,则只能等待该锁定的资源被释放之后,自己才能获取锁定的资源,并添加自己的锁.**而意向锁的作用来了,当一个事务在需要获取一个被锁定的资源时,如果遇到自己需要的资源已经被排它锁占用的时候,该事物可以需要锁定行的表上面增加一个合适的意向锁,如果自己需要一个共享锁,那么就在表上面增加一个意向共享锁,而如果是需要的是某行(或者某些行)上面添加一个排它锁的话,则先在表面增加一个意向排它锁,意向共享锁可以同时存在多个,但是意向排它锁同时存在一个.**

    - **在一个事务想获取一个共享锁之前,他必须先获取一个意向共享锁**

    - **在一个事务想获取一个排它锁之前,他必须先获取一个意向排它锁**

    - **InnoDB 支持多粒度锁,允许行锁和表锁共存**

    - **注意事项**
  
    - **上面说的意向锁是表级锁,表示是一个意向,仅仅表示事务正在读或者写某一行记录,在真正加行锁时才会判断是否冲突.意向锁是innodb自动加的,不需要用户干预**
    
  - **IX,IS是表级锁,不会和行级的X,S发生冲突,只会和表级的X,S发生冲突.**
    
    - InnoDB的锁兼容机制情况
  
      - |                |  S   | X    | IS   | IX   |
        | -------------- | :--: | ---- | ---- | ---- |
        | 共享锁(S)      | 兼容 | 冲突 | 兼容 | 冲突 |
        | 排它锁(X)      | 冲突 | 冲突 | 冲突 | 冲突 |
      | 意向共享锁(IS) | 兼容 | 冲突 | 兼容 | 兼容 |
      | 意向排它锁(IX) | 冲突 | 冲突 | 兼容 | 兼容 |
  
      
  
- **插入意向锁（Insert Intention Locks）**
  
  - 插入意向锁是一种**特殊的间歇锁**,但是不同于间歇锁的是,该锁只用于并发插入操作.如果说间歇锁锁住的是一个区间,那么插入意向锁锁住的就是一个点,
  
- **自增锁（Auto-inc Locks）**
  
  - **预测锁** 
  
  - 死锁和避免死锁
  
    - 概念1
      - **InnoDB的行锁是基于索引实现,所以说如果查询没有命中任何索引,那么Innodb则会使用表锁.另外,Innodb的行锁时针对索引,不针对数据记录,那么访问不同的行,如果使用相同的索引,那么仍然会出现锁冲突.需要注意的是在通过以下**
      - **`select * from table lock in share mode;`**
      - **`select * from table for update;`**
      - **如果表中没有定义任何索引,那么Innodb会创建一个隐藏的聚簇索引并使用这个索引来加锁**
    - 概念2
      - MyISAM 总是一次性获取全部锁
      - InnoDB的锁则是逐步获得,当两个事务都需要获取对方持有的锁,导致双方互相等待,这就产生了死锁,发生死锁后,InnoDB一般可以检测到,并使一个事务释放锁回退,另一个则可以获取锁完成事务.
    - 避免死锁
      - 通过表级锁减少死锁产生概率
      - 多个程序尽量约定相同的顺序访问表(哲学家就餐问题)
      - 同一个事务尽可能做到一次锁定所需要的所有资源

## [**MVCC** (Multiversion Concurrency Control)](https://dev.mysql.com/doc/refman/8.0/en/innodb-multi-versioning.html)

- ### **概括**

  - innodb实在undolog中实现的,通过undolog可以找回数据的历史版本.找回的数据历史版本可以提供给用户读(按照隔离级别的定义,有些读请求只能看到比较老的数据版本),也可以在回滚的时候覆盖数据页上的数据,在innodb内部中,会记录一个全局的活跃的读写事务数组,主要用来判断事务的可见性
  - 可以认为mvcc是行级锁的一个变种,但是它在很多情况下避免了加锁操作,因此开销更低,虽然实现机制有所不同,单大都实现了非阻塞读操作,写操作也只锁定必要的行
  - mvcc的实现有很多种,典型的有乐观并发控制和悲观并发控制
  - mvcc只能在RC和RR两个隔离级别下工作,其他两个隔离级别与mvcc不兼容,因为RU总是读最新的数据行,不符合当前事务版本的数据行,而serializable会对所有读写加锁
  - innodb的mvcc是通过每行记录后面保存的两个隐藏列来事先的,但是并不准确,[官方文档](https://dev.mysql.com/doc/refman/8.0/en/innodb-multi-versioning.html)` InnoDB`向数据库中存储的每一行添加三个字段(DB_TRX_ID,DB_ROLL_PTR,DB_ROW_ID),而不是两个,这三个字段后面说.

- ### [**快照度(一致性读)**](https://dev.mysql.com/doc/refman/8.0/en/innodb-consistent-read.html)

  - **Consistent Nonlocking Reads**(读取undolog中已提交的数据,所以他的读取是非阻塞读取)
  - [**RR和RC隔离界别中一致性读的区别**](https://www.cnblogs.com/digdeep/p/4947694.html)
    - 不同点主要是判断是否提交的**某个时间点**
    - RR
      - RR隔离级别下生成快照的时间点并不是以begin开始的时间作为快照的建立时间点,而是以第一条select语句的时间点作为快照的建立时间点
    - RC
      - 事务中每一次读取都是以当前的时间点作为判断是否提交的实际点，也即是 reads its own fresh snapshot.
    - **RC是语句级多版本(事务的多条只读语句，创建不同的ReadView，代价更高)，RR是事务级多版本(一个ReadView)**

- innodb在数据库每行数据的三个字段

  - 事物ID(DB_TRX_ID): 用来标识最近一次对本行数据做修改(insert|update)的事务标识符,既最后一次(insert|update)本行记录的事务id
  - 回滚指针(DB_ROLL_PTR): 指写入回滚段(rollback sement)的 undo log record(撤销日志记录)
  - DB_ROW_ID: 包含一个随着新行插入而单调自增的行ID,**当由innodb自动产生的聚集索引时,聚集索引会包括这个行ID,否则这个行ID不会出现在任何索引中.**结合聚簇索引的知识点,我的理解是,如果我们表中没有主键或合适的唯一索引,也就是无法生成聚簇索引的时候,innodb会帮我们自动生成聚集索引,单聚簇索引会引用DB_ROW_ID的值来作为主键,如果我们有自己的主键或者合适的唯一索引,那么聚簇索引中也就不会包含DB_ROW_ID

- 三个字段一些理解

  - DB_TRX_ID

    - insert时：创建事务版本号=当前事务DB_TRX_ID
    - update时：旧数据的创建事务版本号不变，复制新增一条记录，创建事务版本号=当前事务DB_TRX_ID
    - delect时：创建事务版本号不变，删除事务版本号=当前事务事务DB_TRX_ID
    - select时：只查询创建事务版本号<=当前事务DB_TRX_ID的记录

  - 1、事务A第一次查询数据，当前DB_TRX_ID=1003，查询create_DB_TRX_ID <= 1003的记录，查出2条记录

    | id   | name | age  | position   | create_DB_TRX_ID | del_DB_TRX_ID |
    | ---- | ---- | ---- | ---------- | ---------------- | ------------- |
    | 1    | 张三 | 24   | 初级程序员 | 1001             | nul           |
    | 2    | 李四 | 25   | 初级程序员 | 1002             | null          |

    

    2、事务B新增一条数据，当前DB_TRX_ID=1004，现在数据表为：

    | id   | name | age  | position   | create_DB_TRX_ID | del_DB_TRX_ID |
    | ---- | ---- | ---- | ---------- | ---------------- | ------------- |
    | 1    | 张三 | 24   | 初级程序员 | 1001             | nul           |
    | 2    | 李四 | 25   | 初级程序员 | 1002             | null          |
    | 3    | 王五 | 28   | 初级程序员 | 1004             | null          |

    3、事务A第二次查询数据，当前DB_TRX_ID还是使用第一次查询时的DB_TRX_ID=1003，查询create_DB_TRX_ID <= 1003的记录，结果还是2条记录，没有问题，mysql通过mvcc解决了快照读时的幻读问题

    4、事务A执行sql：update from users set position='中级程序员' where age > 25;

    更新了数据，当前DB_TRX_ID=1003，查询create_DB_TRX_ID <= 1003的记录，查出3条记录，跟第一次查询的结果不一样，出现幻读问题

    | id   | name | age  | position   | create_DB_TRX_ID | del_DB_TRX_ID |
    | ---- | ---- | ---- | ---------- | ---------------- | ------------- |
    | 1    | 张三 | 24   | 初级程序员 | 1001             | nul           |
    | 2    | 李四 | 25   | 初级程序员 | 1002             | null          |
    | 3    | 王五 | 28   | 初级程序员 | 1004             | 1003          |
    | 4    | 王五 | 28   | 中级程序员 | 1003             | null          |

    对于这种情况,间歇锁是可以解决的,但是不完美,当查询的索引含有唯一属性时,那么next lock key(record key + gap lock)会降级为行锁(record key),这种情况 还是会存在幻读

## log

### undo-log

- 用来回滚行记录到某个版本,一般是逻辑日志,根据每行进行记录
- 当我们对记录做了变更时就会产生undo记录,5.6以后可以使用独立的undo表空间

- undo记录存储的老版本数据,当一个旧的事务需要读取数据时,为了能读取到老版本的数据,需要顺着undo链找到满足其可见性的记录,当版本链很长时,可以以为是个耗时的操作.

- 大多数对数据的变更操作(insert,delete,update),其中insert操作在事务提交前只对当前事物可见,因此undo日志可以在事务提交后直接删除,另外在innodb中update和delete产生的undo日志被归成一类,即**update_undo**

- **在回滚段中undo logs分为 insert undo log 和 update undo log**
  - **insert undo log : 事务对insert新记录时产生的undolog, 只在事务回滚时需要, 并且在事务提交后就可以立即丢弃。**
  - **update undo log : 事务对记录进行delete和update操作时产生的undo log, 不仅在事务回滚时需要, 一致性读也需要，所以不能随便删除，只有当数据库所使用的快照中不涉及该日志记录，对应的回滚日志才会被purge线程删除。**
- 回滚日志保证了事务的原子性

### **redo-log**

-  通常是物理日志,记录的是数据页的物理修改,而不是某一行或某几行修改成怎样怎样
- 他是用来恢复提交后的物理数据页(恢复数据页,且只能恢复到最后一次提交的位置)
- 结构
  - 内存中的日志缓冲(redo log buffer)
  - 磁盘上的重做日志文件(redo log file)
- innodb通过force log at commit机制实现事务的持久性,在事务提交的时候,必须先将该事务的所有事务日志写入到磁盘上的redo log file和undo log file

### **bin-log**

- 作用
  - 二进制文件
  - 记录mysql数据更新或者潜在更新(比如delete语句执行删除而实际并没有符合条件的数据)
  - mysql主从复制
- 三种工作模式
  - Row level
    -  用到mmysql的特殊功能如存储过程,触发器,函数
    - 日志中会记录每一行数据被修改的情况,然后在slave端对相同的数据进行修改
      - 优点: 能清楚记录的每一行数据被修改的细节
      - 缺点: 数据量太大
  - Statement level (默认)
    - 每一条被修改数据的sql都会记录到master的bin-log中,slave在复制的时候sql进程会解析成和原来master端执行过的相同sql在执行,在主从同步一般不建议用,因为有些语句不支持,比如UUID函数,LOAD DATA INFILE (快速导入)语句等
    - 优点: 解决了Row level下的缺点,不需要记录每一行数据的变化,减少bin-log日志量,节约磁盘IO,提高性能
    - 缺点: 容易出现主从复制不一致
  - Mixed(混合模式)
    - 结合了Row level和Statement level的优点，同时binlog结构也更复杂。

## MySql架构

- Server层
  - 连接器
    - 身份校验
    - 需注意一旦身份校验成功,就算被改了权限,如果该用户不断开,则该权限也不会受影响
  - 查询缓存
    - 执行查询语句时会优先查询缓存(8.0移除)
    - 存储以 KEY-VALUE形式存放,value为结果集,key是**查询预计**
    - 如果一个表频繁更新,使用缓存没有必要
  - 分析器
    - 没有命中缓存,SQL语句就会经过分析器,分析这条sql具体干嘛,sql是否正确
    - 第一步,词法分析,一条sql有少个字符串组成,首先提取关键字,比如select,提取出查询的表,字段名字,条件等等
    - 第二步,语法分析,判断sql是否正确,是否符合mysql语法.
  - 优化器
    - 按照MySql认为最优的方案执行
  - 执行器
    - 执行语句,然后从存储引擎中返回数据
    - 执行时首先校验用户权限
- 存储引擎
  - 主要负责数据的存储和读取
- sql执行流程
  - 查询: 权限校验---》查询缓存---》分析器---》优化器---》权限校验---》执行器---》引擎
  - 更新: 分析器----》权限校验----》执行器---》引擎---redo log prepare---》binlog---》redo log commit

## 常见面试题

### 使用自增主键或有序主键好处

- 数据结构考虑,那就是MySql的innodb使用的是B+TREE,是一种平衡树,如果使用的是非自增或无序的,那么就伴随着每次插入数据,Mysql都要做一次再平衡,浪费性能,而,自增或有序的数据,则直接加入最后一个节点即可
- 页分裂问题,mysql底层是以数据页为单位存储的,如果一个页写满了,mysql会申请一个新的数据页,如果使用的是无序主键,那么为了保证索引有序(B+TREE),mysql就会把上一个数据页中的部分数据迁移到新的数据页上,从而造成了页分裂,如果大量移动数据在这个过程中会严重影响插入效率.也会产生碎片,如果要解决这个问题就需要**optimize  [ˈɒptɪmaɪz] TABLE**来重建表并优化填充页面。

### mvcc

- 分类

  - 快照读: 读取的记录是可见的版本,不需要加锁

    - RR隔离级别,开启事务后第一个select
    - RC隔离级别,每次select都会生成快照
    - 实现方式,undolog和mvcc
- 当前读: 读取的是记录的最新版本，并且，当前读返回的记录，都会加上锁，保证其他事务不会再并发修改这条记录
  
  - select .... lock in share mode
    - select .... for update 在事务中才会生效,仅适用于innodb
    - update.delete,insert
    - 实现方式是next-key lock

### 索引的一些问题

- 数据结构
  - b+tree索引: 所有数据存储在叶子节点,复杂度为O(logn),适应范围查找
  - 哈希索引: 适合等值查找,检索效率高,一步到位
- 物理存储纬度
  - 聚簇索引: 聚簇索引就是以主键创建索引,在叶子节点存储表中的数据
  - 非聚簇索引: 以非主键创建索引,在叶子节点存储的是主键和索引列
- 逻辑纬度
  - 主键索引: 
    - 不允许有空值 
    -  ALTER TABLE `table_name` ADD PRIMARY KEY ( `column` ) 
  - 普通索引: 
    - 允许空值和重复值  
    - ALTER TABLE `table_name` ADD INDEX index_name ( `column` )
  - 联合索引: 
    - 多个字段创建的索引,查询时遵循最左匹配原则 
    - ALTER TABLE `table_name` ADD INDEX index_name ( `column1`, `column2`, `column3` )
  - 唯一索引: 
    - 值必须唯一,允许空值  
    - ALTER TABLE `table_name` ADD UNIQUE (`column` ) 
  - 空间索引: 
    - 遵循OpenGIS几何数据模型规则
    -  ALTER TABLE `table_name` ADD FULLTEXT ( `column` )
  - 前缀索引
    - index(field(10)) ,使用该字段的前十个字符串建立索引
    - 前提条件是,前缀的标识度高,比如密码就建立前缀索引,因为密码几乎各不相同
    - 操作难度在于前缀索引截取的长度,我们可以利用`select count(*)/count(distinct left(password,prefixLen));`，通过从调整`prefixLen`的值（从1自增）查看不同前缀长度的一个平均匹配度，接近1时就可以了（表示一个密码的前`prefixLen`个字符几乎能确定唯一一条记录）
- 为什么选择b+tree作为索引结构
  - 与BTREE对比
    - b+tree只在叶子节点存储数据,而btree的非叶子节点也存储数据,所以b+tree单个节点数据量更小,在相同的磁盘IO次数下,b+tree能查询更多的节点
    - b+tree叶子节点使用的是单链表,适合MySql常见的基于范围的顺序查找,而Btree无法做到这一点
  - 与二叉树比较优势
    - 概念
      - 每个节点最多两个子树,分别称为左子树和右子树
      - 左子节点的值小于当前节点的值,右子节点的值大于当前节点的值
      - 顶端的节点称为根节点,没有子节点的节点称为叶子节点
    - 从二叉树的概念可看出,每个父节点最多有两个子节点意味着搜索时的复杂度为O(logN),比B+tree高出不少,二叉树也可能出现一种特殊情况退化成链表复杂度更高
  - 与平衡二叉树比较
    - 平衡二叉树每次的插入或者更新,都需要左旋右旋维持平衡,维护代价太大
    - 如果数据量大,数的高度就会很高,因为数据存在磁盘,那么每次从磁盘读取一个节点,操作的IO次数随之增多
- 索引失效
  - 查询条件包含or，**可能**导致索引失效
    - or两边条件字段,A,B如A不是索引字段,B是索引字段,则B索引失效
    - or两边条件字段,A,B都是索引字段,索引不会失效,如果A,B是范围判断例如<,>不等判断,覆盖率低则索引生效(搜索出来的数据少)
  - 如果字段类型是字符串，where时一定用引号括起来，否则索引失效
  - like通配符可能导致索引失效。
    - select * from table where  name like '333%' 索引生效
    - select * from table where  name like '%333%' 索引失效
    - 如果是覆盖索引则索引生效
  - 联合索引,不符合**最左原则**则索引失效  待商榷..
  - 左连接查询或者右连接查询查询关联的字段编码格式不一样，可能导致索引失效。
  - mysql认为使用全表扫描要比使用索引快,则不使用索引。

### sql执行很慢原因

- 偶尔很慢
  - 数据库在刷脏页
  - 拿不到锁(其他程序,在锁这行数据,或锁表)
- 一直很慢
  - 未使用索引
  - 为正确使用索引,索引未生效
  - 

- mysql刷新脏页是什么
  - 比如我们要向数据库中插入或更新一条数据的时候,数据库会在内存中把数据更新,但是更新后不会立马同步持久化到磁盘中,而是把更新的记录写入redo log中,等到数据库空闲时,在通过redo log里的日志把最新的数据同步到磁盘,但是当内存数据页跟磁盘数据页不一致的时候,我们称这个内存页为**脏页**
  - 脏页的四种场景
    - redolog写满: redo log里的容量是有限的,如果数据库一直很忙,更新有很频繁,这个时候redo log很快就会被写满,这个时候就没办法等空闲的时候再去把数据同步到磁盘,**只能暂停其他操作**,**全身心的把数据同步到磁盘中去**,而这个时候就会出现平时正常的SQL突然变得很慢.
    - **内存不够**:  如果一次性查询的数据比较多,恰好碰到了所查的数据不再内存中,需要申请内存,而此时恰好内存不足,就需要淘汰一部分内存数据页,如果是干净页,就直接释放,**如果是脏页,那么就需要进行刷脏页操作**
    - MySql认为系统**空闲**的时候:这时系统没什么压力(开始刷脏页)
    - Mysql正常关闭的时候: mysql会把内存的脏页都flush到磁盘上,这样下次Mysql启动的时候,就可以直接从磁盘上读取数据,启动速度会很快

# redis

## 常见数据结构

### String

- 数据结构
  - SDS
- 使用场景
  - 计数器(PV)
  - token保存等
  - 分布式锁

### list

- 数据结构
  -  双向列表,可以通过lpush和rpop写入和读取消息
- 使用场景
- 简单的消息队列
  - 注意项,当lpop没有消息时,适当的sleep,这样可以减少服务器压力
  - 如果不想sleep,可以使用blpop,在没有消息时,他会阻塞住,直到消息过来
- 注意,生产后消费了消费就没了

### hash

- 数据结构
  - 类似于java中的Hashmap,内部实现也差不多(数组+链表)
- 使用场景
  - 存储对象,比如一个对象多个属性,id,name,sex,修改的话可以单独修改name

### set

- 数据结构
  - 类似于java的HashSet,redis中是无序集合
- 使用场景
- 可以实现交集,并集等操作,可以用来做共同好友功能

### zSet

- 数据结构
  - 跳表
- 使用场景
  - 对权重排序,排行榜等等
  - 可以用来做延时队列
    - 拿时间戳作为score,消费者使用zrangebyscore指令获取N秒之前的数据轮询处理.

### BitMap

- 位图,其实就是byte数组,二进制表示只有0,1两个数字
- 8个bit组成的一个byte
- 命令
  - 设置值 
    - SETBIT key offset value
    - setbit sign:userid:23333 23 1  设置key  第24位 为 1, 返回值返回之前的值
    - 注意 这里设置的是bit位 
  - 获取值
    - GETBIT key offset
    - 注意 这里offset是bit位
  - 统计数量
    - bitcount key 
    - bitcount key start end
    - 注意 这里的 start end 是 byte,比如 bitcount key 0 0 获取的是 前八个bit位
- 需注意的是设置和读取的offset都是bit值,统计中的start end 是byte
- 使用场景
  - 用户签到

### HyperLogLog

- 命令
  - PFADD key value
  - PFCOUNT key
  - PFMERGE destkey sourcekey
- PF是什么?
  - 它是 HyperLogLog 这个数据结构的发明人 Philippe Flajolet 的首字母缩写

- 实用场景
  - 用来做基数统计的(UV)
    - 什么是基数?
      - 比如数据集 {1, 3, 5, 7, 5, 7, 8}， 那么这个数据集的基数集为 {1, 3, 5 ,7, 8}, 基数(不重复元素)为5
  - 可以解决很多精度要求不高的统计需求
  - 如果我们想知道某一个值是否在hyperloglog里是无能为力的,他没有提供这个方法

### 布隆过滤器

- 原理
  - 是由一串很长的二进制向量组成的,可以看成二进制数组,既然是二进制里面不是0,就是1,初始值是0,例如下面
  - |0|1|0|0|0|0|0|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|
  - 当我们向布隆过滤器加入元素时,我们通过多个hash函数算出一个值,比如hash1(key)=1,hash2(key)=7,hash3(key) = 8,那么我们将该key值第二个格子设为1,第8个格子设置为1,第9个格子设置为1
  - 之后判断该值是否在过滤器中,就可以通过自定义的几个hash函数算出各个的值,只要有一个不是1,我们就可以说该值肯定不存在这个布隆过滤器中
- 优点
  - 二进制组成的数组,内存占用极少,插入查找极快
- 缺点
  - 随着数据越来越多误判率也会增加,无法判断数据一定存在,无法删除数据
- 在redis中布隆过滤器是以一个插件的形式加入

## 持久化

### RDB(快照) 

- 在某个时间点上创建副本,redis默认持久化
- 作用
  - 科技将快照复制到其他服务器从而创建有相同数据的服务器副本(redis 主从结构,主要提升redis性能)
  - 服务器重启时使用
- 配置(Redis.conf)
  - save 900 1 表示在上次创建快照后900s,如果有一个key发生变化则redis会自动触发bgsave命令创建快照
- 对过期键处理
  - 如果服务器以主服务器模式运行,那么载入RDB文件时,程序会对文件中保存的键进行检查,未过期的加载到数据库,如果过期则忽略.
  - 如果服务器以从服务器模式运行,那么载入RDB文件时,文件保存的所有键,不论是否过期,都会被加载到数据库中.因为主从服务器在进行数据同步的时候,从服务器的数据库会被清空,所以一般来说过期键载入也不会对服务器有影响

### AOF(追加文件)

- 开启AOF后执行每一条更改数据的命令,则redis就会将该命令写入硬盘中的AOF文件
- 配置(Redis.conf)
  - 开启  appendonly yes
  - 持久化三种方式
    - appendfsync always   每次修改数据都会写入AOF文件,性能低
    - appendfsync everysec 每秒同步一次,显示地将多个写命令同步到硬盘
    - appendfsync no   让操作系统决定何时同步
- 过期键处理
  - AOF追加写入
    - 如果数据库中某个键已经过期了,但是他还没被惰性删除或者定期删除,那么AOF文件不会因为这个过期键产生任何影响,换句话说就是不管他
    - 当过期键被删除时,那么程序会向AOF追加一个DEL命令,来显示记录该键被删除.
  - AOF重写
    - 在执行AOF重写过程中,程序会对数据库中键做检查,已过期的键不会被保存到重写后的AOF文件中.

### 4.0后持久化(混合模式)

- RDB和AOF混合持久化(默认关闭 )
- 开启配置(AOF也需要开启)
  - appendonly yes
  - aof-use-rdb-preamble yes

## 过期相关

### Redis是如何判断数据是否过期?

- redis维护一个**过期字典**,来保存数据的过期时间
  - 过期字典的键指向数据库中的某一个key
  - 过期字典的值是一个long类型,保存键的过期时间(毫秒经度UNIX时间戳)

### 过期的数据是如何删除的?

- 定时删除(立即删除)
  - 当设置一个过期键时,创建一个回调事件,当过期时间达到时,由**时间处理器**自行执行删除键操作
  - 优点
    - 对内存友好,保证了键过期立即被删除掉,内存也随之释放.
  - 缺点
    - 对CPU是最不友好的,因为删除操作占用cpu时间,如果碰到cpu忙碌时(比如在做交集或排序等计算),会给cpu带来额外的压力
  - 题外话: redis的事件处理器对时间处理器的处理方式是**无序链表**,那么查找一个key的时间复杂度O(N),所以不适合处理大量的时间事件
- 懒惰删除
  - 某个键过期,不会立马被删除掉,而是等待下一次使用时,才会检查到过期,并且删除
  - 优点
    - 对CPU友好
  - 缺点
    - 浪费内存
- 定期删除(基于以上两种的折中方法)
  - 每隔一段时间执行一次删除操作,并且通过限制删除操作的执行时间和频率来减少对cpu时间的影响
  - 实现关键activeExpireCycle
    - 函数每次运行时,都会从一定数量的数据库中取出一定数量的随机键进行检查删除
    - 有个全局变量current_db会记录当前activeExpireCycle函数检查的进度,并且在下一次activeExpireCycle函数调用时,接着上一次的处理进度处理
    - 随着activeExpireCycle的不断执行,服务器中的所有数据库都会被检查一遍后,current_db重置为0,然后开始新的一轮检查工作

### 内存淘汰策略

- 主要是账号怎对redis内存已满

- volatile-lru(least recently used) 从已设置过期时间的数据集中挑选最近最少使用的数据淘汰
- volatile-ttl 从已设置过期时间的数据集中选择快过期的数据进行淘汰
- volatile-random 从已设置过期时间的数据集中随机淘汰数据
- allkeys-lru(least recently used) 当内存不足以容纳新写入的数据时,在键空间中,移除最近最少使用的key
- no-eviction 禁止驱逐数据,也就是说当内存不足以容纳新的数据,新的写入操作会报错
- volatile-lfu(least-frequently-used) 从已设置过期时间的数据集中挑选最不常用的数据进行淘汰
- allkeys-lfu 当内存不足以容纳新写入数据时,在键空间中,移除最不经常使用的key



## 雪崩|穿透|击穿

### 穿透

- 就是大量请求的key不存在与缓存中,导致请求直接打到数据库中
- 解决办法
  - 做好参数校验比如id<0,或者手机号格式不正确等等
  - 缓存无效的key,这种情况不能根本解决问题,比如恶意攻击每次都用不同的key,这样会导致redis中会有大量无用的key,如果非要这种,就设置个失效时间
  - 布隆过滤器

### 击穿

- 指的是一个热点key,访问非常频繁,当这个key失效的瞬间,大量请求打进来,直接请求到数据库中
- 解决办法
  - 缓存永不过期
  - zk或redis实现互斥锁,等待第一个请求构建玩缓存后,释放锁,其他的请求才能通过这个key访问资源

### 雪崩

- 出现情景
  1. reids服务不可用,导致所有请求打到数据库中
  2. 系统缓存模块宕机,造成系统所有请求都访问数据库
- 解决办法
  - 针对第一种情况,采用redis集群
  - 第二种情况就是如果缓存失效问题就在失效时间基础上再加入随机失效时间,或者缓存永远不失效

## redis为什么那么快

### 基于内存实现

- 数据全部放在内存里,类似于HashMap,HashMap的优势就是查找和操作的时间复杂度是O(1)

### 数据结构简单

- 对数据操作也简单,Redis的数据结构都是专门进行设计的

### 单线程

- 参考文章

  -  [为什么 Redis 选择单线程模型](https://draveness.me/whys-the-design-redis-single-thread/)
  - [Redis 6.0与老版性能对比评测](https://mp.weixin.qq.com/s?__biz=MzAwMDU1MTE1OQ==&mid=2653551383&idx=1&sn=dbb30be126970c4d442e9db5c443e1c2&chksm=813a6a8fb64de39967c5f8e9c643563294741a7cb39c667127270feb4e812de0bb98ba2e871a&mpshare=1&scene=1&srcid=&sharer_sharetime=1565068625684&sharer_shareid=7fe10533209031e06134f7321e5b8faa#rd)
  - [Redis6.0新特性及面试题](https://mp.weixin.qq.com/s/FZu3acwK6zrCBZQ_3HoUgw)

- 实现原理

  - **文件事件处理器(file event handler)** 

    - 概念

      - redis基于Reactor模式设计开发了自己的一套高效的事件处理模型.
      - 文件事件处理器是单线程运行的,所以我们一般说redis是单线程模型.

    - 主要构成

      - 多个socket(客户端连接)
      - IO多路复用程序(支持多个客户端连接的关键)
      - 文件事件分派器(将socket关联到相应的事件处理器)
      - 事件处理器(连接应答处理器,命令请求处理器,命令回复处理器)

    - 处理流程

      ![redis事件处理器](redis事件处理器.png)

      

- 优点
  - 避免了不必要的上线文切换和竞争条件
  - 不存在多线程的切换而消耗CPU
  - 不用考虑锁的问题,不存在加锁释放锁操作,也不会出现死锁问题导致的性能损耗

- 4.0 增加多线程主要是针对一些大键值对的删除操作命令,这些命令就会使用主处理外的其它线程处理'异步处理'

- 6.0之前主要还是单线程处理

  - 为什么之前不使用多线程?
    - 单线程变成容易维护
    - redis已经很快了,性能瓶颈不再是CPU,主要是内存和网络
    - 多线程会有死锁,线程上线文切换问题,甚至会影响性能
  - 6.0为什么引入多线程?
    - 提高网络IO读写性能(算是redis中的一个性能瓶颈)
    - 多线程只在网络数据的读写这类耗时操作上使用了,执行命令仍然是单线程执行,所以不必担心线程安全问题

### IO多路复用

- 通过select,poll,epoll监听来自客户端的大量连接(或者说多个socket)
-  I/O 多路复用技术的使用让 Redis 不需要额外创建多余的线程来监听客户端的大量连接，降低了资源的消耗
- 根据套接字关联到不同的事件处理器

## 事物

- 参考文章
  - [知乎](https://zhuanlan.zhihu.com/p/43897838)
- redis不支持回滚,也就是说不支持**原子性**( 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用)

## [高可用](https://www.codedump.info/post/20190409-redis-sentinel/)

### 要求

- 数据备份(冗余)数据冗余在不同的节点,防止数据丢失
- 故障自动切换
- 在线扩容(缩容) 可以根据需要动态增加,减少服务实例

### 主从复制

- 概念
  - 类似于mysql主从同步,从一台redis数据(主节点)复制到其他redis服务器(从节点),且数据复制是单项的,只能从主节点到从节点
  - redis主从复制支持**主从同步**和**从从同步**(后续版本新增,减少主节点的同步负担)
- 原理

  - 旧版本全量复制
    - 原理
      1. 从服务器启动后向主服务器发送**sync**命令
      2. 主服务器收到sync命令后,使用**bgsave**命令生成新的rdb文件,将这个文件同步给从服务器,从服务器清除自己的数据后,载入这个rdb文件.这样状态就会和主服务器执行bgsave命令的时候一致
      3. 然后主服务器将保存在**命令缓冲区**的写命令同步给从服务器,从服务器执行这些命令,这样主从状态就一致了
    - 缺点
      - 全量复制,最大的问题就是,从服务器断线重连后,即便有一部分数据,也需要进行全量复制,效率低
  - 新版本全量复制实现(redis2.8版本)
    - 新版本redis使用psyn命令来代替sync命令,该命令既可以实现完整的全同步也可以实现部分同步
    - 复制偏移量(offset)
      - 执行复制的双方,主从服务器,分别会维护一个复制的偏移量
        - 主服务器每次向从服务器同步N个字节数据之后,将会修改自己的复制偏移量+N
        - 从服务器每次从主服务器同步N个字节数据之后,将会修改自己的复制偏移量+N
    - 复制积压缓冲区(默认1MB)
      - 复制积压缓冲区是有master维护的一个固定长度的FIFO队列,他的作用是缓存已经传播出的命令,当master进行命令传播时,不仅将命令发送给slave,还会将命令写入复制积压缓冲区里面
    - 如何区分全部复制,还是部分复制
      - 服务器运行ID
        - 每个redis服务器,都有其运行ID,运行ID是由服务器在启动的时候自动生成,主服务器会将自己的运行ID发送给从服务器,而从服务器会将主服务器的运行ID保存起来
      - 从服务器redis断线重连之后进行同步操作,就是根据运行ID来判断同步进度
        - 如果从服务器上面保存的主服务器运行ID与当前主服务器运行ID一致,则认为这次断线重连的就是之前复制的主服务器,主服务器可以尝试**部分同步操作**
        - 否则,如果前后两次主服务器运行ID把不同,则进行**完全同步流程**
      - psync命令流程
        1. 客户端向服务器发送slaveof命令,让当前服务器成为slave
        2. 当前服务器根据是否保存master runid来判断是否是第一次复制,如果是第一次同步跳转到3,否则跳转到4
        3. 向master发送 **PSYNC ? -1** 命令,来进行完全同步
        4. 向master发送 psync runid offset
           - 非全量(continue)
             - master接收到psync命令后,首先判断runid是否与本机id一致,如果一致则会再次判断offset偏移量和本机的偏移量相差有没有超过复制积压缓冲区的大小,如果没有就给slave发送continue,此时slave只需等待**master传回失去连接期间的丢失命令**;
           - 全量(fullresync runid offset 或 -err)
             - 如果runid和本机id不一致或者双方offset差距超过了复制积压缓冲区的大小,那么master就会返回**fullresync runid offset**,slave将runid保存起来,并进行完全同步
             - 如果master返回 -err,那么表示master服务器版本低于2.8,识别不了psync命令,此时slave服务器将向master服务器发送sync命令,进行全量同步

- 优缺点
  - 优点
    - 高可靠性
      - 一方面采用双机主备架构,能够在主库出现故障时自动进行主备切换,从库提升为主库提供服务,保证服务平稳运行
      - 另一方面,开启数据持久化功能和配置合理的备份策略,能有效的解决数据误操作和数据异常丢失的问题
    - 读写分离策略: 从节点可以扩展主节点的读能力,有效应对大并发量的读操作
  - 缺点
    - 故障恢复复杂,如果没有 Redis HA系统,当主节点出现故障时,需要手动将一个从节点晋升为主节点,同时需要通知业务方案变更配置,并且需要让其他从库节点复制新主库节点,整个过程需要人为干预,比较繁琐
    - 主库写能力受到单机限制,可以考虑**[分片](https://www.cnblogs.com/shiw27/p/8360485.html)**
    - 主库的存储能力受到单机的限制,可以考虑**[Pika](https://www.cnblogs.com/ExMan/p/11529059.html)**
    - redis主节点低于2.8版本问题,必须全量同步
    - COW机制,导致极端情况下主库内存溢出,程序异常退出或宕机;主库节点生成不备份文件导致服务器磁盘IO和CPU资源消耗,发送GB大小的备份文件导致服务器出口带宽暴增,阻塞请求等等,建议升级新版本[(**reids 4.0重大改进,更好的复制,混合RDB+AOF**)](https://www.cnblogs.com/xuwc/p/14013436.html)

### 哨兵

- 原理
  - redis使用一组哨兵(sentinel) 节点来监控主从redis服务的可用性
  - 一旦发现redis主节点失效,将选举出一个哨兵节点作为领导者(leader)
  - 哨兵的领导者再从剩余的从redis节点中选出一个reids节点作为新的主节点redis对外服务
- 两部分
  - 哨兵节点(sentinel)集群  (2n+1) n>= 1的节数个
    - 负责监控节点运行情况
    - 故障发现
    - 故障转移
    - 配置中心
    - 客户端通知
  - 数据节点集群: 即正常服务客户端请求的redis节点,有主从之分
- 问题
  - 如果对redis数据节点进行监控?
  - 如何确定一个redis数据节点失效?
  - 如何选出一个哨兵节点的领导者?
  - 哨兵节点选择的主redis节点依据是什么?
- 三个监控任务
  - 哨兵节点通过三个定时监控空个任务监控redis数据节点的服务可用性
  - info命令
    - 每隔10s,每隔哨兵节点都会向主从redis服务器发送info命令,获取新的拓扑结构信息
      - 拓扑结构信息
        - 本节点角色:主或者从
        - 主从节点地址,端口信息
    - 这样,哨兵节点就能从info命令中自动获取到从节点信息,因此后续才加入的节点信息,不需要显示配置就能自动感知
  - 向\_sentinel\_:hello频道同步信息(pub/sub)
    - 每隔2s,每隔哨兵节点都会向redis数据节点\_sentinel\_:hello频道同步自身得到的主节点信息及当前哨兵节点的信息,由于其他哨兵节点也订阅了这个频道,因此实际上这个操作可以交换哨兵节点之间的主节点以及哨兵节点的信息
    - 两件事
      - 发现新的哨兵节点,如果有新的哨兵节点加入,此时保存下来新的哨兵节点,后续与该哨兵节点建立连接
      - 交换主节点状态信息,作为后续客观判断主节点下线的依据
  - ping:向数据节点做心跳探测
    - 每隔1S,每隔哨兵节点向主从数据节点和其他sentinel节点发送ping命令,做心跳探测,这个心跳探测是后续主管判断数据节点下线的依据.
- 主观下线和客观下线
  - 主观下线
    - 在心跳探测任务中,如果在配置**down-after-milliseconds**之后,没有收到有效的回复,那个就认为该数据节点**主观下线**
    - 之所以称之为**主观下线**,因为在一个分布式的系统中,有多个机器一起联动工作,网络可能出现各种状态,任凭一个节点的判断,还不足认为一个数据节点下线了,这就需要后面的**客观下线**
  - 客观下线
    - 当一个哨兵认为主节点主观下线时,该哨兵节点需要通过**sentinel is-master-down-by addr**命令向其他哨兵节点咨询该主节点是否下线,如果**超过半数**的节点都回答了下线,此时认为主节点**客观下线**
- 选举哨兵领导者
  - 正如前面所说,当有主节点下线,需要选出一个哨兵节点的领导者,已完成后续选择新的主节点工作
  - 选举的大概流程
    1. 每个哨兵节点通过向其他哨兵节点发送**sentinel is-master-down-by addr**命令来申请成为哨兵领导者.
    2. 每个哨兵节点在收到命令时,只允许给第一个节点投票,其他节点命令,直接拒绝
    3. 如果第一个哨兵节点收到了半数以上的同意票,则升级为哨兵领导者
    4. 如果前三步没有在规定的时间选出一个哨兵领导者,则重新进入下一轮投票
- 选出新的主节点(master)
  - 过滤掉不健康的数据节点
    - 主观下线.
    - 断线的从节点.
    - 五秒内没有回复过哨兵节点ping命令的节点.
    - 与主节点失联的从节点.
  - 选择slave-priority(从节点优先级)最高的从节点,如果存在则返回,不存在则继续走流程.
  - 选择复制偏移量最大的从节点,这就意味着从节点上面的数据最完整,如果存在则返回,不存在继续走流程.
  - 到了这一步所有剩余的从节点状态都是一样的,选择runid最小的从节点.
- 提升新的主节点
  - 哨兵领导者向上一步选出的从节点发送**slaveof no one**命令,让该节点成为主节点
  - 哨兵领导者向剩余的从节点发送命令,让他们成为新的主节点的从节点
  - 哨兵节点集合会将原来主节点更新为从节点,当其回复之后命令他去复制新的主节点数据
- 其他说明
  - slave-priority
    - 仅适用于sentinel模块(unstable,M-S集群管理和监控),需要额外的配置文件支持
    - slave的权重默认为100
    - 当master失效后,sentinel将会从salve列表中找到权重最低(>0)的slave,并提升为master
    - 如果权重值为0,表示此slave为**观察**者,不参加master选举
- 优缺点
  - 优点
    - redis sentinel集群部署简单
    - 能够解决redis主从模式下的高可用切换问题
    - 方便实现redis数据节点的线形扩展,轻松突破redis自身的单线程瓶颈,可以满足大容量或高性能的业务需求
    - 可以实现一套sentinel监控一组redis数据节点或多组数据节点
  - 缺点
    - 部署相对于redis主从模式要复杂些,原理理解更复杂
    - 资源浪费,redis数据节点中的slave作为备份节点不提供服务
    - redis sentinel主要针对redis数据节点的主节点高可用切换,对reids数据节点做失败判定为主观下线和客观下线两种,对redis从节点做主管下线操作,不能执行故障转移
    - 不能解决读写分离问题,实现起来复杂

### 集群

- 介绍
  - 自动将数据进行分片,每个master上放一部分数据
  - 提供内置的高可用支持,部分master不可用时,还可以继续工作
- 关于端口
  - 在redis cluster架构下,每个redis要开放两个端口,比如一个是6379,另一个就是加一万,比如16379
  - 16379端口是用来进行节点通信的,也就是cluster bus的东西,cluster bus的通信,用来进行**故障检测,配置更新,故障转移授权**.cluster bus用另一种二进制协议,**gossip**协议,用于节点间进行高效的数据交换,占用更少的网络带宽和处理时间.
- 节点间的内部通信
  - 基本通信原理(两种方式)
    - 集中式
      - 集中式是将集群元数据(节点信息,故障等等)几种存储在某个节点上.集中式元数据集中存储的一个典型代表,就是大数据领域的**storm**.他是分布式的大数据实时计算引擎.是集中式的元数据存储的结构,底层基于zk对所有元数据进行存储维护
      - 优点
        - 元数据的读取和更新,时效性很好,一旦元数据出现了变更,就立即更新到集中式的存储中,其他节点读取的时候就可以感知到
      - 缺点
        - 所有的元数据的更新压力全部集中在一个地方,可能导致元数据存储有压力
    - gossip[ˈɡɒsɪp]协议
      - 所有节点都持有一份元数据,不同的节点如果出现元数据变更,就不断将元数据发送给其他的节点,让其他节点进行元数据变更
      - 优点
        - 元数据比较分散,不是集中在一个地方,更新请求会陆续打到所有节点上更新,降低了压力
      - 缺点
        - 元数据有延迟,可能导致集群中的一些操作会有一些滞后
  - ping消息探入
    - ping时会携带一些元数据,如果很频繁,可能会加重网络负担
  - 集群模式下redis key寻址(分布式寻址算法)
    - hash算法(大量缓存重建)
      - 对于一个key,首先计算hash值,然后对节点取模,然后打在不同的master节点上,一旦某个master节点宕机,所有请求过来,都会基于最新的剩余的master取模,尝试读取数据,这样导致大部分的请求过来,无法拿到有效的缓存,导致大量流量打到数据库
    - [一致性hash算法](https://zhuanlan.zhihu.com/p/98030096)(自动缓存迁移) + 虚拟节点(自动负载均衡)
      - [与hash算法比较](https://blog.csdn.net/cy973071263/article/details/104497894)
        - 假设有四台redis服务器,用hash算法,我们对key进行hash取模 hash(key) / 4 得到的值一定落到某个redis上,如果其中一个宕机,或者增加一个服务器,所有的数据都乱了
        - 一致性hash算法,只会影响部分数据
    - redis cluster的hash slot算法
      - redis cluster有固定的16384个hash slot,对每个key计算CRC16计算,然后对16384取模,可以获取key对应的hash solt
      - 关于客户端的api,如果让他们走同一个hash slot,可以通过hash tag实现
      - 如果一个机器宕机,另外两个节点不受影响,因为key找到是hash slot,不是机器
  - redis cluster的高可用与主备切换原理(和哨兵非常类似)
    - 判断节点宕机
      - 如果一个节点认为另一个节点宕机,那么就是pfail,主观宕机,如果多个节点都认为一个节点宕机了,那么就是fail,客观宕机,几乎跟哨兵原理一样
      - 在**cluster-node-timeout**内,某个节点一直没返回pong,那么就会被认为pfail
      - 如果一个节点认为某个节点pfail了,那么就会在gossit ping消息中,ping给其他节点,如果超过半数的节点都认为pfail了,那么就会变成fail
    - 从节点过滤
      - 对宕机的master node,从其所有的slave node中,选择一个切换成master node
      - 检查每个slave node 与master node的断开连接时间,如果超过了**cluster-node-timeout * cluster-slave-validity-factor(从节点有效因子,默认为10)**,那么就没资格切换城成master
    - 从节点选举
      - 每个从节点,都根据自己对master复制数据的offset,来使者一个选举时间,offset越大(复制数据越多)的从节点选举时间越靠前,选举时间越靠前,优先进行选举
      - 所有的master node 开始对slave选举投票,给要进行选举的slave进行投票,如果大部分master node(n/2 + 1) 都投给了某个从节点,那么选举通过,那个从节点可以切换成master
      - [另外一种说法](https://blog.csdn.net/m0_37609579/article/details/100609618)

# mongodb

# elasticsearch

### 简介

- elasticSearch是一个分布式可扩展的实时搜索引擎和分析引擎,建立在全文搜索引擎Apache lucene(TM) 基础上的搜索引擎,除了这些还可以做以下工作

  - 分布式实时文件存储,并将每一个字段都编入索引,使其可以被搜索
  - 实时分析的分布式搜索引擎
  - 可扩展到上百台服务器,处理**PB**级别的结构化和非结构化的数据

- es的文件存储是面向文档型的数据库,一条数据就是一个文档,用JSON作为序列化

- 简单对比

  | 关系型数据库 |     数据库      |       表       |         行          |     列     |
  | :----------: | :-------------: | :------------: | :-----------------: | :--------: |
  |    **es**    | **索引(index)** | **类型(Type)** | **文档(documents)** | **fields** |

索引

集群

gc

文章 [1](https://www.cnblogs.com/aspirant/p/11323890.html) [2](https://blog.csdn.net/abcd1101/article/details/89010070)

