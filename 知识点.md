



# JAVA

## 并发

### 线程

- 状态转换

  ![](THREAD_STATE_CHANGE.jpg)

### 关键字与JDK源码

  - #### synchronized [参考链接](http://cmsblogs.com/?p=2071)
    
    - 应用 : A a = new A();
      - 锁普通方法 (锁的是A的实例)
      - 锁静态方法 (锁的是A.class)
      - 锁代码块
        - 对象(a,锁的是A的实例)
        - 类 (A.class,锁的是A.class)
    - 问:当两个线程同时执行A类中的普通方法和静态方法是否互斥?答:不互斥,因为是两把不同的锁
    - 原理(字节码层次,在java语言存在两种语法)
      - 语法
        - 锁 --> 代码块
          - 代码块在源码被编译成bytecode时,会在同步代码的入口位置和退出位置分别插入monitorenter,monitorexit字节指令
        - 锁 --> 方法
          - 在字节码层面没有特别的指令实现被synchronized修饰的方法,而是在Class文件的方法表中将该方法的access_flags字段中的synchronized标志位置1,表示该方法是同步方法并使用调用该方法的对象或者方法所属的Class在jvm的内部对象表示Klass作为对象锁
      - 对象头
        - synchronized用的锁时存在**对象头**里的
        - 对象头主要包括两部分数据(Mark Work, Klass Pointer)
          - Mark Work (标记字段)
          - Klass Pointer (类型指针)
    
  - ##### volatile

  - **LookSupport**

      - 线程等待唤醒机制(相当于wait/notify 加强版)
      - LockSupport通过许可（permit）实现线程挂起、挂起线程唤醒功能。permit可以理解为每个已启动线程维持的一个int类型状态位counter。线程分别通过执行LockSupport静态方法park()、unPark()方法来完成挂起、唤醒操作。
      - 主要方法
          - java.util.concurrent.locks.LockSupport#park()
              - 唤醒条件
                  - unpark()
                      - 当线程执行park时,判断状态位counte为1,表示拥有许可,立马放行,并将状态位counter设置为0
                      - 当线程执行park时,判断状态位counter为0,表示未获得许可,线程阻塞
              - 响应中断
                  - 当其他线程调用了t.interrupt(),locksupport.park()会效应中断
          - java.util.concurrent.locks.LockSupport#unpark(Thread thread)
            - 现将当前状态位counter设置为1
            - 判断当前线程是否被挂起
                - 挂起,则唤起线程,并将counter设为0
                - 未挂起,无任何操作
    - 面试题
      - 先执行unpark在执行park程序会出现什么情况?
        - 先执行unpark,执行线程与locksupport关联的许可(permit)会被设置成1,当执行park时,会进行状态位判断,因为许可被设置成了1,所以表示当前执行的线程拥有许可,立马放行,并将许可设置成0
      - 先唤醒两次,在阻塞两次会出现什么情况?
        - 会阻塞线程
        - 当执行两次unpark时,会将状态位设置为1,且仅为1,状态位counter最大只能设置为1,也就是许可permit最大为1,所以不管先执行几次unpark,都只能唤醒一个park
    
- **ThreadLocal**

     - private final int threadLocalHashCode = nextHashCode();

          - 从方法来看,每次生成ThreadLocal都会进行递增HASH_INCREMENT
     
          - ```java
               private static int nextHashCode() {
                   return nextHashCode.getAndAdd(HASH_INCREMENT);
          }
               ```

     - private static AtomicInteger nextHashCode = new AtomicInteger();

          - 类变量 也就是说每个ThreadLocal实例的nextHashCode是不一样的

     - private static final int HASH_INCREMENT = 0x61c88647;

     - static class ThreadLocalMap
     
          -  每一个Thread都会维护一个只属于当前Thread的ThreadLocalMap
     
          - ```java
               // ThreadLocalMap内部又维护了一个Entry,继承了WeakReference<ThreadLocal<?>>
               static class Entry extends WeakReference<ThreadLocal<?>> {
                   /** The value associated with this ThreadLocal. */
                   // 这个value值就是当前线程要存储的值
                   Object value;
                   Entry(ThreadLocal<?> k, Object v) {
                       // 而传进来的ThreadLocal 交给WeakReference,最后会放入 引用队列
                       super(k);
                       value = v;
                   }
               }
               private static final int INITIAL_CAPACITY = 16;
          private Entry[] table;
               private int size = 0;
               private int threshold;
               ```

          - ```
             
               ```
     
     - java.lang.ThreadLocal#set
     
          - ```java
               public void set(T value) {
                   // 获取当前线程
                   Thread t = Thread.currentThread();
                   ThreadLocalMap map = getMap(t);
                   if (map != null)
                       map.set(this, value);
                   else
                       // 第一次进来map肯定是为null,所以要创建个map
                       createMap(t, value);
               }
               // 获取ThreadLocalMap ,从这里可以看出,Thread中维护着一个ThreadLocalMap
               ThreadLocalMap getMap(Thread t) {
                   return t.threadLocals;
               }
               // Thread中的ThreadLocals 超时是null,此处创建一个ThreadLocalMap,key为ThreadLocal, value为set传入的值
               void createMap(Thread t, T firstValue) {
                   t.threadLocals = new ThreadLocalMap(this, firstValue);
               }
               // ThreadLocalMap的构造器,承接上边的createMap
               ThreadLocalMap(ThreadLocal<?> firstKey, Object firstValue) {
                   // 初始
                   table = new Entry[INITIAL_CAPACITY];
                   int i = firstKey.threadLocalHashCode & (INITIAL_CAPACITY - 1);
                   table[i] = new Entry(firstKey, firstValue);
                   size = 1;
                   setThreshold(INITIAL_CAPACITY);
               }
               // java.lang.ThreadLocal.ThreadLocalMap#set
               private void set(ThreadLocal<?> key, Object value) {
                   Entry[] tab = table;
                   int len = tab.length;
                 	// 初始len=16 ,并且len始终是2^n ,只有这样len-1的二进制表示的就是低位连续的N个1,
                 	// 假设当前线程初始值 threadLocalHashCode = 1640531527  十进制
                 	// len - 1 的       二进制是 1111, 进行补码 00000000 00000000 00000000 00001111
                   // threadLocalHashCode 的二进制位(直接补码) 01100001 11001000 10000110 01000111
                 	// 那么下边的计算得出结果为
                   // 00000000 00000000 00000000 00000111  --> 0111 -> 1*2^2 + 1*2^1 + 1*2^0-> 0+4+2+1=7
                 	// 分析到这也就确定了,当前线程占得table的坑是7,之后当前线程无论多少次ThreadLocal#set 都不会在改变
                 	// 原因在new ThreadLocal<T> 创建实例 时 threadLocalHashCode 的数值已经确定了.
                 	// 需要注意的是 每次new ThreadLocal<T>时threadLocalHashCode 都会以原子性做一个递增操作,而每次都是增加1640531527
                   int i = key.threadLocalHashCode & (len-1);
                   for (Entry e = tab[i];
                        e != null;
                        e = tab[i = nextIndex(i, len)]) {
                    	// e.get() 获取的是一个弱引用的ThreadLocal 	
                     	// 也就是或 当前线程绑定的ThreadLocalMap绑定的弱引用ThreadLocal
                       ThreadLocal<?> k = e.get();
                     	// 如果相等表示是替换value值
                       if (k == key) {
                           e.value = value;
                           return;
                       }
                       // 进入这个条件,也就是说明 出现了gc,并清除了弱引用
                       if (k == null) {
                          
                          replaceStaleEntry(key, value, i);
                          return;
                       }
                   }
                   tab[i] = new Entry(key, value);
                   int sz = ++size;
                   // 如果没有清理并且操作次数大于等于要扩容的条件则进行扩容
                   if (!cleanSomeSlots(i, sz) && sz >= threshold)
                       rehash();
               }
               // java.lang.ThreadLocal.ThreadLocalMap#cleanSomeSlots
               private boolean cleanSomeSlots(int i, int n) {
                   boolean removed = false;
                   Entry[] tab = table;
                   int len = tab.length;
                   do {
                       i = nextIndex(i, len);
                       Entry e = tab[i];
                       if (e != null && e.get() == null) {
                           n = len;
                           removed = true;
                           i = expungeStaleEntry(i);
                       }
                   } while ( (n >>>= 1) != 0);
                   return removed;
               }
               // 调整table大小,删除无用的数据(也就是e.get == null)情况
               // java.lang.ThreadLocal.ThreadLocalMap#rehash
               private void rehash() {
                   expungeStaleEntries();
                   // Use lower threshold for doubling to avoid hysteresis
                   if (size >= threshold - threshold / 4)
                       resize();
               }
               // java.lang.ThreadLocal.ThreadLocalMap#resize
               private void resize() {
                   Entry[] oldTab = table;
                   int oldLen = oldTab.length;
                   int newLen = oldLen * 2;
                   Entry[] newTab = new Entry[newLen];
                   int count = 0;
                   for (int j = 0; j < oldLen; ++j) {
                       Entry e = oldTab[j];
                       if (e != null) {
                           ThreadLocal<?> k = e.get();
                           if (k == null) {
                               e.value = null; // Help the GC
                           } else {
                               int h = k.threadLocalHashCode & (newLen - 1);
                               while (newTab[h] != null)
                                   h = nextIndex(h, newLen);
                               newTab[h] = e;
                               count++;
                           }
                       }
                   }
                   setThreshold(newLen);
                   size = count;
                   table = newTab;
               }
               
               // java.lang.ThreadLocal.ThreadLocalMap#replaceStaleEntry
               private void replaceStaleEntry(ThreadLocal<?> key, Object value,
                                              int staleSlot) {
                   Entry[] tab = table;
                   int len = tab.length;
                   Entry e;
                   // 记录将要删除的slot,这个在清理时是个重要的字段
                   int slotToExpunge = staleSlot;
                   //以staleSlot开始, 向前遍历N个e != null的节点,
                   for (int i = prevIndex(staleSlot, len); (e = tab[i]) != null; i = prevIndex(i, len))
                       if (e.get() == null)
                           // 如果e不为空,e的Key也就是ThreadLocal为空,记录下要删除的slot
                           slotToExpunge = i;
                   
               	// 以staleSlot开始,向后遍历N个 e!=nul的节点
                   for (int i = nextIndex(staleSlot, len);(e = tab[i]) != null; i = nextIndex(i, len)) {
                       ThreadLocal<?> k = e.get();
                       if (k == key) {
                           e.value = value;
                           tab[i] = tab[staleSlot];
                           // staleSlot是调用方法时的计算的槽,此处e赋值给他,代表这个就是最新的了
                           tab[staleSlot] = e;
                           if (slotToExpunge == staleSlot)
                               slotToExpunge = i;
                           cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);
                           return;
                       }
                       if (k == null && slotToExpunge == staleSlot)
                           slotToExpunge = i;
                   }
                   // If key not found, put new entry in stale slot
                   tab[staleSlot].value = null;
                   tab[staleSlot] = new Entry(key, value);
                   // If there are any other stale entries in run, expunge them
                   if (slotToExpunge != staleSlot)
                       cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);
               }
               
               // java.lang.ThreadLocal.ThreadLocalMap#expungeStaleEntry 
               // 清理方法,不做注释了
               private int expungeStaleEntry(int staleSlot) {
                   Entry[] tab = table;
                   int len = tab.length;
                	// 置空
                   tab[staleSlot].value = null;
                   tab[staleSlot] = null;
                   size--;
               
                   Entry e;
                   int i;
                   // 继寻找e!=null的下一个节点,
                   for (i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) {
                       ThreadLocal<?> k = e.get();
                       if (k == null) {
                           e.value = null;
                           tab[i] = null;
                           size--;
                       } else {
                           int h = k.threadLocalHashCode & (len - 1);
                           if (h != i) {
                               tab[i] = null;
                               while (tab[h] != null)
                                   h = nextIndex(h, len);
                               tab[h] = e;
                           }
                       }
                   }
                   return i;
               }
               
               ```
     
     - java.lang.ThreadLocal#get
     
          - ```java
               public T get() {
                   Thread t = Thread.currentThread();
                   ThreadLocalMap map = getMap(t);  // Thread.threadLocals
                   if (map != null) {
                       ThreadLocalMap.Entry e = map.getEntry(this);
                       if (e != null) {
                           @SuppressWarnings("unchecked")
                           T result = (T)e.value;
                           return result;
                       }
                   }
                   return setInitialValue();
               }
               // java.lang.ThreadLocal.ThreadLocalMap#getEntry
               private Entry getEntry(ThreadLocal<?> key) {
                   int i = key.threadLocalHashCode & (table.length - 1);
                   Entry e = table[i];
                   if (e != null && e.get() == key)
                       return e;
                   else
                       return getEntryAfterMiss(key, i, e);
               }
               
               // java.lang.ThreadLocal.ThreadLocalMap#getEntryAfterMiss
               // 该方法通过一个while条件获取entry,直到 找到与当先线程相等的ThreadLocal
               // 如果找不到,直接返回空
               // 该方法也涉及删除无效的entry
               private Entry getEntryAfterMiss(ThreadLocal<?> key, int i, Entry e) {
                   Entry[] tab = table;
                   int len = tab.length;
                   while (e != null) {
                       ThreadLocal<?> k = e.get();
                       if (k == key)
                           return e;
                       if (k == null)
                           expungeStaleEntry(i);
                       else
                           i = nextIndex(i, len);
                       e = tab[i];
                   }
                   return null;
               }
               ```
     
     - java.lang.ThreadLocal#remove
     
          - ```
               private void remove(ThreadLocal<?> key) {
                   Entry[] tab = table;
                   int len = tab.length;
                   int i = key.threadLocalHashCode & (len-1);
                   for (Entry e = tab[i];
                        e != null;
                        e = tab[i = nextIndex(i, len)]) {
                       if (e.get() == key) {
                           e.clear();
                           expungeStaleEntry(i);
                           return;
                       }
                   }
               }
               ```

### J.U.C

- 中断
  - 关键方法
    - java.lang.Thread#isInterrupted()   --- public boolean isInterrupted()
      - 会调用private native boolean isInterrupted(boolean ClearInterrupted) 本地方法,true代表重置,false代表不重置,此处ClearInterrupted=false
      -  测试线程是否已经中断。线程的中断状态不受该方法的影响
    - java.lang.Thread#interrupted   --- public static boolean interrupted()
      - 会调用private native boolean isInterrupted(boolean ClearInterrupted) 本地方法,true代表重置,false代表不重置,此处ClearInterrupted=true
      - 测试当前线程是否已经中断。如果线程处于中断状态返回true，否则返回false。同时该方法将清除的线程的中断状态。即，如果连续两次调用该方法，则第二次调用将返回 false。该方法可用于清除线程中断状态使用。
      - 
    - java.lang.Thread#interrupt ---- public void interrupt()
      - 中断线程
- 
  
 - AQS (抽象的队列同步器) [源码解读](https://www.cnblogs.com/waterystone/p/4920797.html)

    - ![](CLH队列.png)

    - AQS中维护一个CLH变种的双端队列,和一个volatile 修饰的state字段

       - state 字段 0 值表示空闲没有任何线程占用,大于0表示有线程正在使用
       - Node 内部类
          - static final Node SHARED = new Node();   共享锁标识
          - static final Node EXCLUSIVE = null; // 共享锁
          - static final int CANCELLED =  1; 
          - static final int SIGNAL    = -1;
          - static final int CONDITION = -2;
          - static final int PROPAGATE = -3;
          - volatile int waitStatus; //初始值 0
          - volatile Node prev; 前指针
          - volatile Node next; 后指针
          - volatile Thread thread; 当前node的线程
          - Node nextWaiter;
       - Node head 头结点
       - Node tail 尾节点

    - 流程 (以ReentrantLock为例)

       - new ReentrantLock() 初始化,默认使用非公平锁(NonfairSync)

       - lock

         - ```java
           final void lock() {
               if (compareAndSetState(0, 1))
                   setExclusiveOwnerThread(Thread.currentThread());
               else
                   acquire(1);
           ```

           

         - 当state=0时也就是说没有任何线程占用锁,cas操作成功,将state从0设置成1,并且返回true,然后设置拥有锁的线程,也就是当前线程

         - 当state !=0,也就是已经有线程占有锁了,表示cas操作失败,进入acquire(1);方法

         - ```java
           public final void acquire(int arg) {
               if (!tryAcquire(arg) &&
                   acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
                   // 当acqioreQueued返回true则表示当前线程不是被unpark唤醒的,是被其他线程中断唤醒的,所以要自我中断一次,将中断标志位设为true
                   // 原因是因为,当前线程在阻塞时没有及时响应中断信号,现在要进行补偿,这样的话,如果该线程在lock代码块内部调用sleep()之类的阻塞方法
                   // 就可以抛出异常,响应中断
                 selfInterrupt();
           }
           ```
           
         - 此时tryAcquire(arg)会再次尝试获取一下锁,如果成功后边的方法就不用再执行了

           - ```java
             protected final boolean tryAcquire(int acquires) {
                 return nonfairTryAcquire(acquires);
             }
             final boolean nonfairTryAcquire(int acquires) {
                 // 获取当前线程
                 final Thread current = Thread.currentThread();
                 int c = getState();
                 // 如果c = 0 也就是state=0尝试cas强锁
                 if (c == 0) {
                     // 强锁成功的话设置当前线程为持有锁线程并返回true
                     if (compareAndSetState(0, acquires)) {
                         setExclusiveOwnerThread(current);
                         return true;
                     }
                 }
                 // 如果c!=0 也就是state!=0判断,持有锁的线程是不是当前线程(重入锁逻辑)
                 else if (current == getExclusiveOwnerThread()) {
                     int nextc = c + acquires;
                     if (nextc < 0) // overflow
                         throw new Error("Maximum lock count exceeded");
                     setState(nextc);
                     return true;
                 }
                 return false;
             }
             ```

         - 当tryAcquire(arg) 失败,则继续向后执行

           - ```java
             private Node addWaiter(Node mode) {
             	// 创建一个node节点,mode 区分为 共享锁/独占锁,此处是以ReentrantLock为例,
             	// 所以此处是独占锁Node.EXCLUSIVE
                 Node node = new Node(Thread.currentThread(), mode);
                 // 将尾节点赋值给pred
                 Node pred = tail;
                 if (pred != null) {
                     node.prev = pred;
                     // 将新创建的node设置成尾节点
                     if (compareAndSetTail(pred, node)) {
                         pred.next = node;
                         return node;
                     }
                 }
                 enq(node);
                 return node;
             }
             private Node enq(final Node node) {
             	// 一个自旋
                 for (;;) {
                     Node t = tail;
                     // 第一次进来t 肯定是null
                     if (t == null) { // Must initialize
                     	// 此处创建了一个node实例并将这个实例放置到头结点
                         // 该节点也叫哨兵节点/傀儡节点,只是占位使用
                         if (compareAndSetHead(new Node()))
                         	如果CAS设置成功 将将尾节点赋值
                             tail = head;
                     } else {
                         //当 t != null时进入此处
                         node.prev = t;
                         //CAS 操作将尾节点设置成enq入参的node
                         if (compareAndSetTail(t, node)) {
                             // CAS 操作成功,设置t的next节点为node并返回
                             t.next = node;
                             return t;
                         }
                     }
                 }
             }
             ```

             - enq第一次图(t==null)![](enq_one.png)
             - enq第二次图(t!=null)![](enq_two.png)

         - enq方法执行完成后执行acquireQueued(final Node node, int arg) 方法

           - ```java
             final boolean acquireQueued(final Node node, int arg) {
                 boolean failed = true;
                 try {
                     boolean interrupted = false;
                     // 自旋
                     for (;;) {
                         // 获取node的前置节点,该方法会抛出一个npe异常
                         final Node p = node.predecessor();
                         //如果node的前置节点是头结点,则再次尝试抢锁
                         if (p == head && tryAcquire(arg)) {
                             // 抢锁成功设置当前节点为头节点也就是傀儡节点
                             setHead(node);
                             // 将之前的头结点next引用改为null,方便gc
                             // 换句话说就是之前的头结点p已经给任何node没有应用关系了
                             p.next = null; // help GC
                             failed = false;
                             return interrupted;
                         }
                         // 当shouldParkAfterFailedAcquire=true
                         // parkAndCheckInterrupt=false (表示未被中断)
                         // parkAndCheckInterrupt=true (表示被中断) 并赋值interrupted = true;
                         // 此时线程已被前一个node节点唤醒,并且前一个节点已经晋升为头结点,当前线程开始进入下一次自旋
                         if (shouldParkAfterFailedAcquire(p, node) &&
                             parkAndCheckInterrupt())
                             interrupted = true;
                     }
                 } finally {
                     if (failed)
                         cancelAcquire(node);
                 }
             }
             private void setHead(Node node) {
                 head = node;
                 node.thread = null;
                 node.prev = null;
             }
             private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) {
                 int ws = pred.waitStatus;
                 if (ws == Node.SIGNAL)
                     /*
                      * This node has already set status asking a release
                      * to signal it, so it can safely park.
                      */
                     return true;
                 if (ws > 0) {
             		// 当被取消的线程才会进入这里
                     do {
                         node.prev = pred = pred.prev;
                     } while (pred.waitStatus > 0);
                     pred.next = node;
                 } else {
             		// waitStatus的默认值是0,所以第一次进来会进入这里
                     // 执行一个CAS操作,将waitStatus 赋值成SINNAL(-1)
                     compareAndSetWaitStatus(pred, ws, Node.SIGNAL);
                 }
                 return false;
             }
             private final boolean parkAndCheckInterrupt() {
                 // 挂起线程 阻塞在这里了,等待被unpark
                 LockSupport.park(this);
                 // 获取当前线程是否被中断过,并恢复默认中断状态(false)
                 return Thread.interrupted();
             }
             ```

       - 释放锁

         - ```java
           public void unlock() {
               sync.release(1);
           }
           public final boolean release(int arg) {
               if (tryRelease(arg)) {
                   Node h = head;
                   if (h != null && h.waitStatus != 0)
                       unparkSuccessor(h);
                   return true;
               }
               return false;
           }
           protected final boolean tryRelease(int releases) {
               int c = getState() - releases;
               // 在释放锁时,如果不是当前线程占有的锁,则抛出异常
               if (Thread.currentThread() != getExclusiveOwnerThread())
                   throw new IllegalMonitorStateException();
               boolean free = false;
               // 如果c==0表示可以释放锁了,如果非0表示当前线程是重入锁
               if (c == 0) {
                   free = true;
                   setExclusiveOwnerThread(null);
               }
               // 直接setState值,而不是使用CAS,因为reentranLock的addWaiter(Node.EXCLUSIVE) 用的是排它锁,
               // 所以此时直接set即可,此时是没有线程来抢锁的
               setState(c);
               return free;
           }
           // node 传进来的是头结点,也是当前线程的node节点
           private void unparkSuccessor(Node node) {
                   int ws = node.waitStatus;
                   if (ws < 0)
                       compareAndSetWaitStatus(node, ws, 0);
                   Node s = node.next;
                   if (s == null || s.waitStatus > 0) {
                       s = null;
                       for (Node t = tail; t != null && t != node; t = t.prev)
                           if (t.waitStatus <= 0)
                               s = t;
                   }
                   if (s != null)
                       // 唤醒下一个线程
                       
                       LockSupport.unpark(s.thread);
               }
           ```

- ThreadPoolExecutor
  - 构造方法参数
    - int corePoolSize       
    - int maximumPoolSize
    - long keepAliveTime
    - TimeUnit unit
    - BlockingQueue<Runnable> workQueue
    - ThreadFactory threadFactory
    - RejectedExecutionHandler handler
    
  - 成员变量和类变量

    - ```java
      // 初始 -536870912
      // 该字段控制状态,ctl 封装了 两个字段
      // workerCount 有效的线程数量
      // runState 该字段表明当前线程池 是否是在运行或者停止等等
      // ctl一个变量同时存储runState和workerCount，其中runState占用高3位，workCount占用低29位
      // 每增加一个线程则ctl原子性加一
      private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));
      private static final int COUNT_BITS = Integer.SIZE - 3;  // 29
      // 00011111 11111111 11111111 11111111
      private static final int CAPACITY   = (1 << COUNT_BITS) - 1; // 536870911
      // runState is stored in the high-order bits 
      // 11100000 00000000 00000000 00000000
      private static final int RUNNING    = -1 << COUNT_BITS; // -536870912
      // 00000000 00000000 00000000 00000000
      private static final int SHUTDOWN   =  0 << COUNT_BITS; // 0
      // 00100000 00000000 00000000 00000000
      private static final int STOP       =  1 << COUNT_BITS; // 536870912
      // tidying  [ˈtaɪdiɪŋ]  使整洁;使整齐 ;使有条理;整理
      // 01000000 00000000 00000000 00000000
      private static final int TIDYING    =  2 << COUNT_BITS; // 1073741824
      // terminated [ˈtɜːmɪneɪtɪd] 终止,结束
      // 01100000 00000000 00000000 00000000
      private static final int TERMINATED =  3 << COUNT_BITS; // 1610612736
      
      // Packing and unpacking ctl
      // 解析出来 runState
      // CAPACITY取反 高三位 变成了 111
      // c 如果在 -1 到 -536870912 之间 则表示线程是在运行中状态
      private static int runStateOf(int c)     { return c & ~CAPACITY; }
      // worker线程数量
      private static int workerCountOf(int c)  { return c & CAPACITY; }
      private static int ctlOf(int rs, int wc) { return rs | wc; }
      ```

  - ![大体流程](线程池流程.png)

  - 知识点

    - ThreadPoolExecutor中的内部类Worker简单描述下

      - ```java
        private final class Worker extends AbstractQueuedSynchronizer, implements Runnable {
        	// 通过构造方法可以看出,这个线程是通过工厂创建出来的,如果用户自定义线程工程,则使用用户的线程工厂,
            // 否则使用默认的工厂创建一个新的线程
            final Thread thread;
            // 通过构造方法可以看出,这个存放的就是线程池提交进来要执行的任务
        	Runnable firstTask;
            // 任务计数器
        	volatile long completedTasks;
        
        	Worker(Runnable firstTask) {
                setState(-1); // inhibit interrupts until runWorker
                this.firstTask = firstTask;
                this.thread = getThreadFactory().newThread(this);
            }
            // 省略重写的AbstractQueuedSynchronizer方法
            // 省略实现的Runnable方法
            
            // 下边就是Worker自己的方法了,可以看出Worker类本身就是一把锁
            
        	public void lock()        { acquire(1); }
        	public boolean tryLock()  { return tryAcquire(1); }
        	public void unlock()      { release(1); }
        	public boolean isLocked() { return isHeldExclusively(); }
        
        	void interruptIfStarted() {
        	    Thread t;
            	if (getState() >= 0 && (t = thread) != null && !t.isInterrupted()) {
                	try {
                    	t.interrupt();
                	} catch (SecurityException ignore) {
                	}
            	}
        	}
        }
        ```

      - Worker为什么要继承AbstractQueuedSynchronizer?意义何在?

        - ```java
          //下边是重写AbstractQueuedSynchronizer的方法
          // 该方法重写之后,只是简单的判断了下 state的值是否等于0
          protected boolean isHeldExclusively() {
              return getState() != 0;
          }
          
          protected boolean tryAcquire(int unused) {
              if (compareAndSetState(0, 1)) {
                  setExclusiveOwnerThread(Thread.currentThread());
                  return true;
              }
              return false;
          }
          // 独占锁,在释放锁时无需考虑线程安全,所以直接将占用锁的线程置空,直接调用setState方法,将state置为0
          protected boolean tryRelease(int unused) {
              setExclusiveOwnerThread(null);
              setState(0);
              return true;
          }	
          ```

      - Worker为什么要实现Runnable接口?

        - ```java
          // 实现了Runnable接口的方法
          public void run() {
              runWorker(this);
          }
          // 被run方法调用
          final void runWorker(Worker w) {
              Thread wt = Thread.currentThread();
              Runnable task = w.firstTask;
              w.firstTask = null;
              w.unlock(); // allow interrupts
              boolean completedAbruptly = true;
              try {
                  while (task != null || (task = getTask()) != null) {
                      w.lock();
                      if ((runStateAtLeast(ctl.get(), STOP) ||(Thread.interrupted() 
                           && runStateAtLeast(ctl.get(), STOP))) &&  !wt.isInterrupted()) 
                          wt.interrupt();
                      try {
                          beforeExecute(wt, task);
                          Throwable thrown = null;
                          try {
                              task.run();
                          } catch (RuntimeException x) {
                              thrown = x; throw x;
                          } catch (Error x) {
                              thrown = x; throw x;
                          } catch (Throwable x) {
                              thrown = x; throw new Error(x);
                          } finally {
                              afterExecute(task, thrown);
                          }
                      } finally {
                          task = null;
                          w.completedTasks++;
                          w.unlock();
                      }
                  }
                  completedAbruptly = false;
              } finally {
                  processWorkerExit(w, completedAbruptly);
              }
          }
          ```

          


# spring

## 事务

## MVC调用过程

## Bean生命周期

## Bean 循环依赖

## spring.handles 文件

## BeanFactory 和 FactoryBean<T>

## spring一些类说明

### class

- AbstractAutowireCapableBeanFactory
  - 实例化bean
  - 属性填充
  - 初始化bean
  - 三级缓存
- DefaultListableBeanFactory
- AbstractApplicationContext
- LazyInitializationBeanFactoryPostProcessor
- AbstractBeanDefinition
- PostProcessorRegistrationDelegatez
- SimpleApplicationEventMulticaster
- ConfigurationClassPostProcessor
- CommonAnnotationBeanPostProcessor
  - 类层次
    - 继承 InitDestroyAnnotationBeanPostProcessor   
    - 实现 InstantiationAwareBeanPostProcessor
    - 实现 BeanFactoryAware
    - 实现 Serializable
  - 
- AutowiredAnnotationBeanPostProcessor
  - 间接实现两种BeanPostProcessor
    - SmartInstantiationAwareBeanPostProcessor
      - determineCandidateConstructors(构造器实例化推断)
        - 调用时机:实例化之前
        - 在实例化bean之前调用,用来推断是否是通过有参构造器实例化还是用无参构造器初始化.
          - AbstractAutowireCapableBeanFactory#autowireConstructor(有参数构造器构建)
          - AbstractAutowireCapableBeanFactory#instantiateBean (无参构造器实例化)
        - lookup处理,如果存在lookup注解,则包装一个 LookupOverride override = new LookupOverride(method, lookup.value())类,然后将lookup包装后实例 放入 RootBeanDefinition.methodOverrides(字段中维护了一个Set集合,说明可以有多个lookup注解) 字段中,便于以后使用,CGLIB提升.
      - postProcessProperties
        - 调用时机:实例化之后,填充属性
        - 属性注入 包括@autowired  @value  @javax.inject.Inject
        - 内部类
          - AutowiredFieldElement extends InjectionMetadata.InjectedElement
          - AutowiredMethodElement extends InjectionMetadata.InjectedElement
          - 以上两个类包装 要注入的属性
    - MergedBeanDefinitionPostProcessor
      - postProcessMergedBeanDefinition
        - 调用时机:目标bean实例化后
  - 实现 BeanFactoryAware,主要作用 aware回调 setBeanFactory
  - 实现 PriorityOrdered 接口
    - 用于排序,该接口继承Order接口,无任何方法,算是个标识,在排序逻辑中PriorityOrdered比Order接口更强
- SimpleTypeConverter
- ResourceEditorRegistrar
  - registerCustomEditors
- PropertyPlaceholderHelper
- SmartInitializingSingleton
- PropertySourcesPropertyResolver
- AbstractPropertyResolver
- AbstractBeanFactory
- SimpleInstantiationStrategy
- InitDestroyAnnotationBeanPostProcessor

### interface

- InstantiationAwareBeanPostProcessor
- MergedBeanDefinitionPostProcessor
  - void postProcessMergedBeanDefinition(RootBeanDefinition beanDefinition, Class<?> beanType, String beanName)
    - 在bean实例化之后,立即调用可以修改beandefinition中的properties ,或缓存一些meta信息例如
  - void resetBeanDefinition(String beanName) 
    - 该方法是根据beanName 重置beandefinition
- BeanPostProcessor
  - Object postProcessBeforeInitialization(Object bean, String beanName)
    - 该方法在bean属性注入之后执行,自定义 init方法或InitializingBean的afterPropertiesSet方法之前
    - 返回一个原始bean或包装后的bean,如果返回null,就不会在执行后续的BeanPostProcessors的子类了
  - Object postProcessAfterInitialization(Object bean, String beanName)
    - 在执行InitializingBean#afterPropertiesSet()方法或自定义init方法后执行
    - 返回一个原始的bean或包装过的bean,如果返回null,就不会在执行后续的BeanPostProcessors的子类了
- BeanDefinition
- ApplicationContext
- BeanFactoryPostProcessors
- Lifecycle
- DisposableBean
- ApplicationContextInitializer
- ConversionService
- ObjectFactory<T>
  - objectfactory设计是用来对特定bean进行加工的，比如需要进行aop代理，需要对bean个性化的时候可以用objectfactory包装一下，objectprovider一般是spring内部实现某一个功能时可能有考虑不到的地方，spring抽象一个接口类型然后通过objectprovide来进行延长查找你实现了这些接口的类，一般会设计成链式调用，我个人的理解是objectfactory用来增强bean的功能，objectprovide+特点功能扩展接口，来实现把我们的功能和spring内部逻辑整合，比如@configurationpropertys不能解析spel表达式但是spring提供了扩展接口和objectprovide功能，我通过这2个地方扩展出来使得@configurationpropertys也能像@value一样支持spel表达式（springboot2.3才支持的！）
- InstantiationStrategy
- InjectionMetadata
- CglibSubclassingInstantiationStrategy
- DestructionAwareBeanPostProcessor

## Spring boot是如何内嵌TOMCAT的?

## Spring annotation

- @LookUp,单例引用原型(prototype)
  - 解释:Spring容器中单例A通过@Autowired或@resource 引入原型Bean,会出现原型bean变成了单例,而不是每次调用都会创建成新的实例所以lookup可以解决

# MYSQL

## 索引

 - ## BTree索引

    -   **MyISAM:** 
        -   MyISAM索引文件和数据文件是分离的
        -   B+Tree叶节点的data域存放的是数据记录的地址。
        -   在索引检索的时候，首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其 data 域的值，然后以 data 域的值为地址读取相应的数据记录。这被称为“非聚簇索引”。
    -   **InnoDB:** 
        -   其数据文件本身就是索引文件。
        -   其表数据文件本身就是按B+Tree组织的一个索引结构，树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。这被称为“聚簇索引（或聚集索引）”。
        -   其余的索引都作为辅助索引，辅助索引的data域存储相应记录主键的值而不是地址，这也是和MyISAM不同的地方。**在根据主索引搜索时，直接找到key所在的节点即可取出数据；在根据辅助索引查找时，则需要先取出主键的值，再走一遍主索引。** **因此，在设计表的时候，不建议使用过长的字段作为主键，也不建议使用非单调的字段作为主键，这样会造成主索引频繁分裂。**

 - ## [哈希索引](https://www.zhihu.com/question/67094336)

   	-   **底层的数据结构就是哈希表，因此在绝大多数需求为单条记录查询的时候，可以选择哈希索引，查询性能最快**
         	-   **mysql的 Memory存储引擎显示的支持了哈希索引**
            	-   **InnoDB引擎有一个特殊的功能叫做自适应哈希索引,当Innodb注意到默写索引值被使用的非常频繁时,他会在内存中机遇B-tree索引只上在创建一个哈希索引,这样就能让b-tree也具有哈希索引的一些优点,注:这是完全自动的,内部行为,用户无法控制和配置的,如果有必要可以关闭这个功能.**
   
- 辅助索引

  - 空间索引,主要用于地理空间数据类型
  - 全文索引,查找文本中的关键字,用于全文检索
  - 普通索引,最基本的索引,没有限制,唯一的任务就是加快对数据的访问速度.
  - 唯一索引,与普通索引类似,但是唯一索引值必须唯一,允许空值,单是是组合索引,则列值的组合必须唯一.
  - 主键索引,innodb聚簇索引
  - 组合索引
  
- 拓展

    - [索引下推(index conditoin pushdown 简称ICP)](https://blog.csdn.net/sinat_29774479/article/details/103470244)
        - 概述
            - 在不使用ICP的情况下，在使用**非主键索引（又叫普通索引或者二级索引）**进行查询时,存储引擎通过索引检索到数据,然后返回给MySQL服务器，服务器然后判断数据是否符合条件 。
            - 在使用ICP的情况下,如果存在某些被索引的列的判断条件时,MySQL服务器将这一部分判断条件传递给存储引擎,然后由存储引擎通过判断索引是否符合MySQL服务器传递的条件,只有当索引符合条件时才会将数据检索出来返回给MySQL服务器 
        - 注意项
            - innodb引擎只适用于二级索引(辅助索引), 因为innodb的聚簇索引会将正行数据读到innodb的缓冲区,ICP的主要目的减少IO次数就是去了意义,因为数据已经在内存中了,不需要在读取了
            - 引用子查询不能下推
            - 调用存储过程的条件不能下推,因为存储引擎无法调用位于Mysql服务器中的存储过程
            - 触发条件不能下推
        - 工作过程
            - 不使用: 获取下一行数据,首先读取索引信息,然后根据索引将正行数据读出来,然后通过where条件判断当前条件是否符合
            - 使用: 获取下一行索引信息,检索索引中的存储列信息是否符合索引条件,如果符合将整行数据读出来,如果不符合则跳过读取下一行,用剩余的判断条件,判断慈航数据是否符合,符合则返回数据

## 事务

- **ACID**

  - **原子性（Atomicity）：** 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；
  - **一致性（Consistency）：** 执行事务后，数据库从一个正确的状态变化到另一个正确的状态；
  - **隔离性（Isolation）：** 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；
    - **持久性（Durability）：** 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。

- **并发事务带来的问题**

  - **脏读（Dirty read）** 
    - 当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是不正确的。
    - 指一个线程中的事务读取到了另外一个线程中未提交的数据。
  - **丢失修改（Lost to modify）**
    -  指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。 例如：事务1读取某表中的数据A=20，事务2也读取A=20，事务1修改A=A-1，事务2也修改A=A-1，最终结果A=19，事务1的修改被丢失。
  - **不可重复读（Unrepeatableread）**  <!--**mysql的默认级别**--> 
    - 指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。
    - 指一个线程中的事务读取到了另外一个线程中提交的update的数据。
  - **幻读（Phantom read）**
    -  幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。
    - 指一个线程中的事务读取到了另外一个线程中提交的insert的数据。
  - **特别说明不可重复读的重点是修改比如多次读取一条记录发现其中某些列的值被修改，幻读的重点在于新增或者删除比如多次读取一条记录发现记录增多或减少了。**

- **隔离级别**

  - **READ-UNCOMMITTED(读取未提交)：** 最低的隔离级别，允许读取尚未提交的数据变更，**可能会导致脏读、幻读或不可重复读**。

  - **READ-COMMITTED(读取已提交)：** 允许读取并发事务已经提交的数据，**可以阻止脏读，但是幻读或不可重复读仍有可能发生**。

  - **REPEATABLE-READ(可重复读)：** 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，**可以阻止脏读和不可重复读，但幻读仍有可能发生**。

  - **SERIALIZABLE(可串行化)：** 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，**该级别可以防止脏读、不可重复读以及幻读**。

    

  - | 隔离级别         | 脏读 | 不可重复读 | 幻影读 |
    | ---------------- | ---- | ---------- | ------ |
    | READ-UNCOMMITTED | √    | √          | √      |
    | READ-COMMITTED   | ×    | √          | √      |
    | REPEATABLE-READ  | ×    | ×          | √      |
    | SERIALIZABLE     | ×    | ×          | ×      |

  - 特别说明mysql默认的隔离级别是 **可重复读**  使用的是next-key lock锁因此可以避免幻读产生,所以说mysql的可重复读已经完全可以保证事务的隔离要求.既达到了sql标准的可串行化隔离级别
  
- 事物的开始时间

  - 一般我们会认为begin/start transaction 是事物的开始时间点,其实是错误的,事务的真正开始时间点(LSN) 是start transaction 之后执行的第一条语句,不管什么语句,不管成功与否.但是如果你想要达到将 start transaction 作为事务开始的时间点，那么我们必须使用 2
    1. **START TRANSACTION** 时，是第一条语句的执行时间点，就是事务开始的时间点，第一条select语句建立一致性读的snapshot；
    2. **START TRANSACTION WITH consistent snapshot** 时，则是立即建立本事务的一致性读snapshot，当然也开始事务了；
  
- 总结

  - 原子性: undo log,实现回滚
  - 持久性: redo log 从而达到故障后恢复
  - 隔离性: 使用锁和mvcc,使用的优化思想有读写分离,读读并行,读写并行
  - 一致性: 通过回滚,以及恢复,和在并发环境下的隔离达到的一致性

## [锁](https://blog.csdn.net/Saintyyu/article/details/91269087?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-1.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-1.control)

- 表锁

  - 存储引擎支持
    - innodb
    - Myisam
  - 概要
    - 对整张表枷锁
    - 实现简单,资源消耗较少
    - 加锁快
    - 不会出现死锁
    - **触发锁冲突的概率较高**

- 行锁
  - 存储引擎支持
    - innodb
    - Myisam
  - 概要
    - 只对行加锁
    - 减少数据库操作冲突
    - 并发度高
    - 加锁开销大,加锁慢
    - **会出现死锁**
  - 行锁也分几种
    - **Record Lock**:   对索引项加锁,锁定符合条件的行,**其他事务不能修改和删除加锁项**
    - **Gap Lock:**对索引项的**'间歇'**进行加锁,锁定的范围(对第一条记录之前的间歇或最后一条将要记录后的间歇加锁),不包含索引项本身,其他事务不能再缩范围内插入数据,**这样就防止别的事务新增幻影行.**
    - **Next-Key Lock:** 锁定索引项本身和索引范围,既Record lock + gap lock的结合,可解决幻读的问题
- 以上三种锁注意事项
    - innodb对于行的查询使用next-key lock
    - Next-locking keying为了解决Phantom Problem幻读问题
    - 当查询的索引含有唯一属性时，将next-key lock降级为record key
    - Gap锁设计的目的是为了阻止多个事务将记录插入到同一范围内，而这会导致幻读问题的产生
    - 有两种方式显式关闭gap锁：（除了外键约束和唯一性检查外，其余情况仅使用record lock） A. 将事务隔离级别设置为RC B. 将参数innodb_locks_unsafe_for_binlog设置为1
  
- 锁分类

  - 共享锁(S)

    - **Share Locks**,也可称之为读锁
    - 例如事务T对数据A加S锁,则事务T只能读A,其他事务也只能对数据A加S锁,而不能加X锁,直到T释放了A锁.

  - 排它锁(X)

    - **Exclusive lock**又称之为写锁
    - 例如事务T对数据A加X锁,则只允许T读取和修改数据A,其他事务不能再对数据A进行任何类型的锁,直到T释放了A上的锁.

  - [意向锁](https://dev.mysql.com/doc/refman/8.0/en/innodb-locking.html#innodb-intention-locks)(**表级**)

    - 当一个事务需要给自己需要的某个资源加锁的时候,如果遇到一个共享锁正在锁定自己需要的资源的时候,自己可以在加一个共享锁,**不过不能加排他锁.**但是,如果遇到自己需要锁定的资源已经被一个排它锁占有之后,则只能等待该锁定的资源被释放之后,自己才能获取锁定的资源,并添加自己的锁.**而意向锁的作用来了,当一个事务在需要获取一个被锁定的资源时,如果遇到自己需要的资源已经被排它锁占用的时候,该事物可以需要锁定行的表上面增加一个合适的意向锁,如果自己需要一个共享锁,那么就在表上面增加一个意向共享锁,而如果是需要的是某行(或者某些行)上面添加一个排它锁的话,则先在表面增加一个意向排它锁,意向共享锁可以同时存在多个,但是意向排它锁同时存在一个.**

    - **在一个事务想获取一个共享锁之前,他必须先获取一个意向共享锁**

    - **在一个事务想获取一个排它锁之前,他必须先获取一个意向排它锁**

    - **InnoDB 支持多粒度锁,允许行锁和表锁共存**

    - **注意事项**
  
    - **上面说的意向锁是表级锁,表示是一个意向,仅仅表示事务正在读或者写某一行记录,在真正加行锁时才会判断是否冲突.意向锁是innodb自动加的,不需要用户干预**
    
  - **IX,IS是表级锁,不会和行级的X,S发生冲突,只会和表级的X,S发生冲突.**
    
    - InnoDB的锁兼容机制情况
  
      - |                |  S   | X    | IS   | IX   |
        | -------------- | :--: | ---- | ---- | ---- |
        | 共享锁(S)      | 兼容 | 冲突 | 兼容 | 冲突 |
        | 排它锁(X)      | 冲突 | 冲突 | 冲突 | 冲突 |
      | 意向共享锁(IS) | 兼容 | 冲突 | 兼容 | 兼容 |
      | 意向排它锁(IX) | 冲突 | 冲突 | 兼容 | 兼容 |
  
      
  
- **插入意向锁（Insert Intention Locks）**
  
  - 插入意向锁是一种**特殊的间歇锁**,但是不同于间歇锁的是,该锁只用于并发插入操作.如果说间歇锁锁住的是一个区间,那么插入意向锁锁住的就是一个点,
  
- **自增锁（Auto-inc Locks）**
  
  - **预测锁** 
  
  - 死锁和避免死锁
  
    - 概念1
      - **InnoDB的行锁是基于索引实现,所以说如果查询没有命中任何索引,那么Innodb则会使用表锁.另外,Innodb的行锁时针对索引,不针对数据记录,那么访问不同的行,如果使用相同的索引,那么仍然会出现锁冲突.需要注意的是在通过以下**
      - **`select * from table lock in share mode;`**
      - **`select * from table for update;`**
      - **如果表中没有定义任何索引,那么Innodb会创建一个隐藏的聚簇索引并使用这个索引来加锁**
    - 概念2
      - MyISAM 总是一次性获取全部锁
      - InnoDB的锁则是逐步获得,当两个事务都需要获取对方持有的锁,导致双方互相等待,这就产生了死锁,发生死锁后,InnoDB一般可以检测到,并使一个事务释放锁回退,另一个则可以获取锁完成事务.
    - 避免死锁
      - 通过表级锁减少死锁产生概率
      - 多个程序尽量约定相同的顺序访问表(哲学家就餐问题)
      - 同一个事务尽可能做到一次锁定所需要的所有资源

## [**MVCC** (Multiversion Concurrency Control)](https://dev.mysql.com/doc/refman/8.0/en/innodb-multi-versioning.html)

- ### **概括**

  - innodb实在undolog中实现的,通过undolog可以找回数据的历史版本.找回的数据历史版本可以提供给用户读(按照隔离级别的定义,有些读请求只能看到比较老的数据版本),也可以在回滚的时候覆盖数据页上的数据,在innodb内部中,会记录一个全局的活跃的读写事务数组,主要用来判断事务的可见性
  - 可以认为mvcc是行级锁的一个变种,但是它在很多情况下避免了加锁操作,因此开销更低,虽然实现机制有所不同,单大都实现了非阻塞读操作,写操作也只锁定必要的行
  - mvcc的实现有很多种,典型的有乐观并发控制和悲观并发控制
  - mvcc只能在RC和RR两个隔离级别下工作,其他两个隔离级别与mvcc不兼容,因为RU总是读最新的数据行,不符合当前事务版本的数据行,而serializable会对所有读写加锁
  - innodb的mvcc是通过每行记录后面保存的两个隐藏列来事先的,但是并不准确,[官方文档](https://dev.mysql.com/doc/refman/8.0/en/innodb-multi-versioning.html)` InnoDB`向数据库中存储的每一行添加三个字段(DB_TRX_ID,DB_ROLL_PTR,DB_ROW_ID),而不是两个,这三个字段后面说.

- ### [**快照度(一致性读)**](https://dev.mysql.com/doc/refman/8.0/en/innodb-consistent-read.html)

  - **Consistent Nonlocking Reads**(读取undolog中已提交的数据,所以他的读取是非阻塞读取)
  - [**RR和RC隔离界别中一致性读的区别**](https://www.cnblogs.com/digdeep/p/4947694.html)
    - 不同点主要是判断是否提交的**某个时间点**
    - RR
      - RR隔离级别下生成快照的时间点并不是以begin开始的时间作为快照的建立时间点,而是以第一条select语句的时间点作为快照的建立时间点
    - RC
      - 事务中每一次读取都是以当前的时间点作为判断是否提交的实际点，也即是 reads its own fresh snapshot.
    - **RC是语句级多版本(事务的多条只读语句，创建不同的ReadView，代价更高)，RR是事务级多版本(一个ReadView)**

- innodb在数据库每行数据的三个字段

  - 事物ID(DB_TRX_ID): 用来标识最近一次对本行数据做修改(insert|update)的事务标识符,既最后一次(insert|update)本行记录的事务id
  - 回滚指针(DB_ROLL_PTR): 指写入回滚段(rollback sement)的 undo log record(撤销日志记录)
  - DB_ROW_ID: 包含一个随着新行插入而单调自增的行ID,**当由innodb自动产生的聚集索引时,聚集索引会包括这个行ID,否则这个行ID不会出现在任何索引中.**结合聚簇索引的知识点,我的理解是,如果我们表中没有主键或合适的唯一索引,也就是无法生成聚簇索引的时候,innodb会帮我们自动生成聚集索引,单聚簇索引会引用DB_ROW_ID的值来作为主键,如果我们有自己的主键或者合适的唯一索引,那么聚簇索引中也就不会包含DB_ROW_ID

- 三个字段一些理解

  - DB_TRX_ID

    - insert时：创建事务版本号=当前事务DB_TRX_ID
    - update时：旧数据的创建事务版本号不变，复制新增一条记录，创建事务版本号=当前事务DB_TRX_ID
    - delect时：创建事务版本号不变，删除事务版本号=当前事务事务DB_TRX_ID
    - select时：只查询创建事务版本号<=当前事务DB_TRX_ID的记录

  - 1、事务A第一次查询数据，当前DB_TRX_ID=1003，查询create_DB_TRX_ID <= 1003的记录，查出2条记录

    | id   | name | age  | position   | create_DB_TRX_ID | del_DB_TRX_ID |
    | ---- | ---- | ---- | ---------- | ---------------- | ------------- |
    | 1    | 张三 | 24   | 初级程序员 | 1001             | nul           |
    | 2    | 李四 | 25   | 初级程序员 | 1002             | null          |

    

    2、事务B新增一条数据，当前DB_TRX_ID=1004，现在数据表为：

    | id   | name | age  | position   | create_DB_TRX_ID | del_DB_TRX_ID |
    | ---- | ---- | ---- | ---------- | ---------------- | ------------- |
    | 1    | 张三 | 24   | 初级程序员 | 1001             | nul           |
    | 2    | 李四 | 25   | 初级程序员 | 1002             | null          |
    | 3    | 王五 | 28   | 初级程序员 | 1004             | null          |

    3、事务A第二次查询数据，当前DB_TRX_ID还是使用第一次查询时的DB_TRX_ID=1003，查询create_DB_TRX_ID <= 1003的记录，结果还是2条记录，没有问题，mysql通过mvcc解决了快照读时的幻读问题

    4、事务A执行sql：update from users set position='中级程序员' where age > 25;

    更新了数据，当前DB_TRX_ID=1003，查询create_DB_TRX_ID <= 1003的记录，查出3条记录，跟第一次查询的结果不一样，出现幻读问题

    | id   | name | age  | position   | create_DB_TRX_ID | del_DB_TRX_ID |
    | ---- | ---- | ---- | ---------- | ---------------- | ------------- |
    | 1    | 张三 | 24   | 初级程序员 | 1001             | nul           |
    | 2    | 李四 | 25   | 初级程序员 | 1002             | null          |
    | 3    | 王五 | 28   | 初级程序员 | 1004             | 1003          |
    | 4    | 王五 | 28   | 中级程序员 | 1003             | null          |

    对于这种情况,间歇锁是可以解决的,但是不完美,当查询的索引含有唯一属性时,那么next lock key(record key + gap lock)会降级为行锁(record key),这种情况 还是会存在幻读

## log

- ### undo-log

  - 用来回滚行记录到某个版本,一般是逻辑日志,根据每行进行记录
  - 当我们对记录做了变更时就会产生undo记录,5.6以后可以使用独立的undo表空间

  - undo记录存储的老版本数据,当一个旧的事务需要读取数据时,为了能读取到老版本的数据,需要顺着undo链找到满足其可见性的记录,当版本链很长时,可以以为是个耗时的操作.

  - 大多数对数据的变更操作(insert,delete,update),其中insert操作在事务提交前只对当前事物可见,因此undo日志可以在事务提交后直接删除,另外在innodb中update和delete产生的undo日志被归成一类,即**update_undo**

  - **在回滚段中undo logs分为 insert undo log 和 update undo log**
    - **insert undo log : 事务对insert新记录时产生的undolog, 只在事务回滚时需要, 并且在事务提交后就可以立即丢弃。**
    - **update undo log : 事务对记录进行delete和update操作时产生的undo log, 不仅在事务回滚时需要, 一致性读也需要，所以不能随便删除，只有当数据库所使用的快照中不涉及该日志记录，对应的回滚日志才会被purge线程删除。**
  - 回滚日志保证了事务的原子性

- ### **redo-log**

  -  通常是物理日志,记录的是数据页的物理修改,而不是某一行或某几行修改成怎样怎样
  - 他是用来恢复提交后的物理数据页(恢复数据页,且只能恢复到最后一次提交的位置)
  - 结构
    - 内存中的日志缓冲(redo log buffer)
    - 磁盘上的重做日志文件(redo log file)
  - innodb通过force log at commit机制实现事务的持久性,在事务提交的时候,必须先将该事务的所有事务日志写入到磁盘上的redo log file和undo log file

- ## **bin-log**

  - 作用
    - 二进制文件
    - 记录mysql数据更新或者潜在更新(比如delete语句执行删除而实际并没有符合条件的数据)
    - mysql主从复制
  - 三种工作模式
    - Row level
      -  用到mmysql的特殊功能如存储过程,触发器,函数
      - 日志中会记录每一行数据被修改的情况,然后在slave端对相同的数据进行修改
        - 优点: 能清楚记录的每一行数据被修改的细节
        - 缺点: 数据量太大
    - Statement level (默认)
      - 每一条被修改数据的sql都会记录到master的bin-log中,slave在复制的时候sql进程会解析成和原来master端执行过的相同sql在执行,在主从同步一般不建议用,因为有些语句不支持,比如UUID函数,LOAD DATA INFILE (快速导入)语句等
      - 优点: 解决了Row level下的缺点,不需要记录每一行数据的变化,减少bin-log日志量,节约磁盘IO,提高性能
      - 缺点: 容易出现主从复制不一致
    - Mixed(混合模式)
      - 结合了Row level和Statement level的优点，同时binlog结构也更复杂。

## MySql架构

- Server层
  - 连接器
    - 身份校验
    - 需注意一旦身份校验成功,就算被改了权限,如果该用户不断开,则该权限也不会受影响
  - 查询缓存
    - 执行查询语句时会优先查询缓存(8.0移除)
    - 存储以 KEY-VALUE形式存放,value为结果集,key是**查询预计**
    - 如果一个表频繁更新,使用缓存没有必要
  - 分析器
    - 没有命中缓存,SQL语句就会经过分析器,分析这条sql具体干嘛,sql是否正确
    - 第一步,词法分析,一条sql有少个字符串组成,首先提取关键字,比如select,提取出查询的表,字段名字,条件等等
    - 第二步,语法分析,判断sql是否正确,是否符合mysql语法.
  - 优化器
    - 按照MySql认为最优的方案执行
  - 执行器
    - 执行语句,然后从存储引擎中返回数据
    - 执行时首先校验用户权限
- 存储引擎
  - 主要负责数据的存储和读取
- sql执行流程
  - 查询: 权限校验---》查询缓存---》分析器---》优化器---》权限校验---》执行器---》引擎
  - 更新: 分析器----》权限校验----》执行器---》引擎---redo log prepare---》binlog---》redo log commit

## 常见面试题

- 使用自增主键或有序主键好处

  - 数据结构考虑,那就是MySql的innodb使用的是B+TREE,是一种平衡树,如果使用的是非自增或无序的,那么就伴随着每次插入数据,Mysql都要做一次再平衡,浪费性能,而,自增或有序的数据,则直接加入最后一个节点即可
  - 页分裂问题,mysql底层是以数据页为单位存储的,如果一个页写满了,mysql会申请一个新的数据页,如果使用的是无序主键,那么为了保证索引有序(B+TREE),mysql就会把上一个数据页中的部分数据迁移到新的数据页上,从而造成了页分裂,如果大量移动数据在这个过程中会严重影响插入效率.也会产生碎片,如果要解决这个问题就需要**optimize  [ˈɒptɪmaɪz] TABLE**来重建表并优化填充页面。
- mvcc

  - 分类

    - 快照读: 读取的记录是可见的版本,不需要加锁

      - RR隔离级别,开启事务后第一个select
      - RC隔离级别,每次select都会生成快照
      - 实现方式,undolog和mvcc
  - 当前读: 读取的是记录的最新版本，并且，当前读返回的记录，都会加上锁，保证其他事务不会再并发修改这条记录
    
    - select .... lock in share mode
      - select .... for update 在事务中才会生效,仅适用于innodb
      - update.delete,insert
      - 实现方式是next-key lock
    

- 索引的一些问题
  - 数据结构
    - b+tree索引: 所有数据存储在叶子节点,复杂度为O(logn),适应范围查找
    - 哈希索引: 适合等值查找,检索效率高,一步到位
  - 物理存储纬度
    - 聚簇索引: 聚簇索引就是以主键创建索引,在叶子节点存储表中的数据
    - 非聚簇索引: 以非主键创建索引,在叶子节点存储的是主键和索引列
  - 逻辑纬度
    - 主键索引: 
      - 不允许有空值 
      -  ALTER TABLE `table_name` ADD PRIMARY KEY ( `column` ) 
    - 普通索引: 
      - 允许空值和重复值  
      - ALTER TABLE `table_name` ADD INDEX index_name ( `column` )
    - 联合索引: 
      - 多个字段创建的索引,查询时遵循最左匹配原则 
      - ALTER TABLE `table_name` ADD INDEX index_name ( `column1`, `column2`, `column3` )
    - 唯一索引: 
      - 值必须唯一,允许空值  
      - ALTER TABLE `table_name` ADD UNIQUE (`column` ) 
    - 空间索引: 
      - 遵循OpenGIS几何数据模型规则
      -  ALTER TABLE `table_name` ADD FULLTEXT ( `column` )
  - 为什么选择b+tree作为索引结构
    - 与BTREE对比
      - b+tree只在叶子节点存储数据,而btree的非叶子节点也存储数据,所以b+tree单个节点数据量更小,在相同的磁盘IO次数下,b+tree能查询更多的节点
      - b+tree叶子节点使用的是单链表,适合MySql常见的基于范围的顺序查找,而Btree无法做到这一点
    - 与二叉树比较优势
      - 概念
        - 每个节点最多两个子树,分别称为左子树和右子树
        - 左子节点的值小于当前节点的值,右子节点的值大于当前节点的值
        - 顶端的节点称为根节点,没有子节点的节点称为叶子节点
      - 从二叉树的概念可看出,每个父节点最多有两个子节点意味着搜索时的复杂度为O(logN),比B+tree高出不少,二叉树也可能出现一种特殊情况退化成链表复杂度更高
    - 与平衡二叉树比较
      - 平衡二叉树每次的插入或者更新,都需要左旋右旋维持平衡,维护代价太大
      - 如果数据量大,数的高度就会很高,因为数据存在磁盘,那么每次从磁盘读取一个节点,操作的IO次数随之增多
  - 索引失效
    - 查询条件包含or，**可能**导致索引失效
      - or两边条件字段,A,B如A不是索引字段,B是索引字段,则B索引失效
      - or两边条件字段,A,B都是索引字段,索引不会失效,如果A,B是范围判断例如<,>不等判断,覆盖率低则索引生效(搜索出来的数据少)
    - 如果字段类型是字符串，where时一定用引号括起来，否则索引失效
    - like通配符可能导致索引失效。
      - select * from table where  name like '333%' 索引生效
      - select * from table where  name like '%333%' 索引失效
      - 如果是覆盖索引则索引生效
    - 联合索引,不符合**最左原则**则索引失效  待商榷..
    - 左连接查询或者右连接查询查询关联的字段编码格式不一样，可能导致索引失效。
    - mysql认为使用全表扫描要比使用索引快,则不使用索引。

